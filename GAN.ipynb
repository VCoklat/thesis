{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42bf1f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T08:29:37.352428Z",
     "iopub.status.busy": "2025-01-06T08:29:37.352043Z",
     "iopub.status.idle": "2025-01-06T09:36:24.579581Z",
     "shell.execute_reply": "2025-01-06T09:36:24.578487Z"
    },
    "papermill": {
     "duration": 4007.232851,
     "end_time": "2025-01-06T09:36:24.581449",
     "exception": false,
     "start_time": "2025-01-06T08:29:37.348598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of classes: 7\n",
      "Class labels: ['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
      "100%|██████████| 82.7M/82.7M [00:01<00:00, 67.6MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x1-5666bf0f80.pth\n",
      "100%|██████████| 8.79M/8.79M [00:00<00:00, 41.9MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Batch [0], D_loss: 6.4733, D_adv: 2.0022, D_rec: 0.4471, G_loss: -0.5366\n",
      "Epoch [0/100], Batch [100], D_loss: 1.6680, D_adv: 1.4949, D_rec: 0.0173, G_loss: -0.0954\n",
      "Epoch [1/100], Batch [0], D_loss: 1.5017, D_adv: 1.3749, D_rec: 0.0127, G_loss: -0.1084\n",
      "Epoch [1/100], Batch [100], D_loss: 1.2674, D_adv: 1.1825, D_rec: 0.0085, G_loss: -0.0260\n",
      "Epoch [2/100], Batch [0], D_loss: 1.2974, D_adv: 1.2169, D_rec: 0.0080, G_loss: -0.0355\n",
      "Epoch [2/100], Batch [100], D_loss: 2.1056, D_adv: 2.0349, D_rec: 0.0071, G_loss: -0.6197\n",
      "Epoch [3/100], Batch [0], D_loss: 1.2411, D_adv: 1.1781, D_rec: 0.0063, G_loss: -0.0200\n",
      "Epoch [3/100], Batch [100], D_loss: 1.2126, D_adv: 1.1410, D_rec: 0.0072, G_loss: -0.0082\n",
      "Epoch [4/100], Batch [0], D_loss: 1.1309, D_adv: 1.0819, D_rec: 0.0049, G_loss: -0.0096\n",
      "Epoch [4/100], Batch [100], D_loss: 1.2427, D_adv: 1.1559, D_rec: 0.0087, G_loss: -0.0157\n",
      "Epoch [5/100], Batch [0], D_loss: 1.3304, D_adv: 1.2624, D_rec: 0.0068, G_loss: -0.1263\n",
      "Epoch [5/100], Batch [100], D_loss: 1.1361, D_adv: 1.0891, D_rec: 0.0047, G_loss: -0.0071\n",
      "Epoch [6/100], Batch [0], D_loss: 1.1966, D_adv: 1.1472, D_rec: 0.0049, G_loss: -0.0056\n",
      "Epoch [6/100], Batch [100], D_loss: 1.1239, D_adv: 1.0777, D_rec: 0.0046, G_loss: -0.0044\n",
      "Epoch [7/100], Batch [0], D_loss: 1.1965, D_adv: 1.1444, D_rec: 0.0052, G_loss: -0.0165\n",
      "Epoch [7/100], Batch [100], D_loss: 1.1733, D_adv: 1.1268, D_rec: 0.0047, G_loss: -0.0086\n",
      "Epoch [8/100], Batch [0], D_loss: 1.1392, D_adv: 1.0854, D_rec: 0.0054, G_loss: -0.0039\n",
      "Epoch [8/100], Batch [100], D_loss: 1.1484, D_adv: 1.1019, D_rec: 0.0047, G_loss: -0.0050\n",
      "Epoch [9/100], Batch [0], D_loss: 1.1063, D_adv: 1.0608, D_rec: 0.0045, G_loss: -0.0042\n",
      "Epoch [9/100], Batch [100], D_loss: 1.1362, D_adv: 1.0675, D_rec: 0.0069, G_loss: -0.0044\n",
      "Epoch [10/100], Batch [0], D_loss: 1.1183, D_adv: 1.0661, D_rec: 0.0052, G_loss: -0.0038\n",
      "Epoch [10/100], Batch [100], D_loss: 1.0996, D_adv: 1.0550, D_rec: 0.0045, G_loss: -0.0036\n",
      "Epoch [11/100], Batch [0], D_loss: 1.0882, D_adv: 1.0541, D_rec: 0.0034, G_loss: -0.0034\n",
      "Epoch [11/100], Batch [100], D_loss: 1.1081, D_adv: 1.0636, D_rec: 0.0044, G_loss: -0.0038\n",
      "Epoch [12/100], Batch [0], D_loss: 1.0955, D_adv: 1.0569, D_rec: 0.0039, G_loss: -0.0064\n",
      "Epoch [12/100], Batch [100], D_loss: 1.1507, D_adv: 1.1007, D_rec: 0.0050, G_loss: -0.0093\n",
      "Epoch [13/100], Batch [0], D_loss: 1.0899, D_adv: 1.0405, D_rec: 0.0049, G_loss: -0.0034\n",
      "Epoch [13/100], Batch [100], D_loss: 1.2181, D_adv: 1.1730, D_rec: 0.0045, G_loss: -0.0794\n",
      "Epoch [14/100], Batch [0], D_loss: 1.2539, D_adv: 1.2014, D_rec: 0.0053, G_loss: -0.0069\n",
      "Epoch [14/100], Batch [100], D_loss: 1.4286, D_adv: 1.3527, D_rec: 0.0076, G_loss: -0.0831\n",
      "Epoch [15/100], Batch [0], D_loss: 1.0418, D_adv: 1.0081, D_rec: 0.0034, G_loss: -0.0028\n",
      "Epoch [15/100], Batch [100], D_loss: 1.0330, D_adv: 1.0039, D_rec: 0.0029, G_loss: -0.0022\n",
      "Epoch [16/100], Batch [0], D_loss: 1.0324, D_adv: 1.0035, D_rec: 0.0029, G_loss: -0.0020\n",
      "Epoch [16/100], Batch [100], D_loss: 1.0369, D_adv: 1.0075, D_rec: 0.0029, G_loss: -0.0019\n",
      "Epoch [17/100], Batch [0], D_loss: 1.0400, D_adv: 1.0033, D_rec: 0.0037, G_loss: -0.0015\n",
      "Epoch [17/100], Batch [100], D_loss: 1.0578, D_adv: 1.0254, D_rec: 0.0032, G_loss: -0.0143\n",
      "Epoch [18/100], Batch [0], D_loss: 1.0469, D_adv: 1.0116, D_rec: 0.0035, G_loss: -0.0063\n",
      "Epoch [18/100], Batch [100], D_loss: 1.3196, D_adv: 1.2779, D_rec: 0.0042, G_loss: -0.7359\n",
      "Epoch [19/100], Batch [0], D_loss: 1.0616, D_adv: 1.0055, D_rec: 0.0056, G_loss: -0.0010\n",
      "Epoch [19/100], Batch [100], D_loss: 1.0598, D_adv: 1.0252, D_rec: 0.0035, G_loss: -0.0044\n",
      "Epoch [20/100], Batch [0], D_loss: 1.0802, D_adv: 1.0509, D_rec: 0.0029, G_loss: -0.0062\n",
      "Epoch [20/100], Batch [100], D_loss: 1.0506, D_adv: 1.0108, D_rec: 0.0040, G_loss: -0.0116\n",
      "Epoch [21/100], Batch [0], D_loss: 1.0587, D_adv: 1.0024, D_rec: 0.0056, G_loss: -0.0016\n",
      "Epoch [21/100], Batch [100], D_loss: 1.0381, D_adv: 1.0026, D_rec: 0.0035, G_loss: -0.0012\n",
      "Epoch [22/100], Batch [0], D_loss: 1.7529, D_adv: 1.7088, D_rec: 0.0044, G_loss: -0.0235\n",
      "Epoch [22/100], Batch [100], D_loss: 1.0653, D_adv: 1.0063, D_rec: 0.0059, G_loss: -0.0023\n",
      "Epoch [23/100], Batch [0], D_loss: 1.0529, D_adv: 1.0211, D_rec: 0.0032, G_loss: -0.0024\n",
      "Epoch [23/100], Batch [100], D_loss: 1.0391, D_adv: 1.0053, D_rec: 0.0034, G_loss: -0.0013\n",
      "Epoch [24/100], Batch [0], D_loss: 1.0438, D_adv: 1.0055, D_rec: 0.0038, G_loss: -0.0042\n",
      "Epoch [24/100], Batch [100], D_loss: 1.0663, D_adv: 1.0257, D_rec: 0.0041, G_loss: -0.0042\n",
      "Epoch [25/100], Batch [0], D_loss: 2.0641, D_adv: 1.9937, D_rec: 0.0070, G_loss: -0.4081\n",
      "Epoch [25/100], Batch [100], D_loss: 1.0342, D_adv: 1.0014, D_rec: 0.0033, G_loss: -0.0006\n",
      "Epoch [26/100], Batch [0], D_loss: 1.0576, D_adv: 1.0011, D_rec: 0.0056, G_loss: -0.0008\n",
      "Epoch [26/100], Batch [100], D_loss: 1.0247, D_adv: 1.0007, D_rec: 0.0024, G_loss: -0.0006\n",
      "Epoch [27/100], Batch [0], D_loss: 1.0330, D_adv: 1.0007, D_rec: 0.0032, G_loss: -0.0005\n",
      "Epoch [27/100], Batch [100], D_loss: 2.0488, D_adv: 2.0062, D_rec: 0.0043, G_loss: -0.0353\n",
      "Epoch [28/100], Batch [0], D_loss: 1.8308, D_adv: 1.7947, D_rec: 0.0036, G_loss: -0.0995\n",
      "Epoch [28/100], Batch [100], D_loss: 1.0489, D_adv: 1.0202, D_rec: 0.0029, G_loss: -0.0013\n",
      "Epoch [29/100], Batch [0], D_loss: 1.7642, D_adv: 1.7304, D_rec: 0.0034, G_loss: -0.1296\n",
      "Epoch [29/100], Batch [100], D_loss: 1.0279, D_adv: 1.0016, D_rec: 0.0026, G_loss: -0.0010\n",
      "Epoch [30/100], Batch [0], D_loss: 1.0339, D_adv: 1.0012, D_rec: 0.0033, G_loss: -0.0009\n",
      "Epoch [30/100], Batch [100], D_loss: 1.0273, D_adv: 1.0006, D_rec: 0.0027, G_loss: -0.0003\n",
      "Epoch [31/100], Batch [0], D_loss: 1.0308, D_adv: 1.0009, D_rec: 0.0030, G_loss: -0.0005\n",
      "Epoch [31/100], Batch [100], D_loss: 1.0351, D_adv: 1.0008, D_rec: 0.0034, G_loss: -0.0003\n",
      "Epoch [32/100], Batch [0], D_loss: 1.0443, D_adv: 1.0005, D_rec: 0.0044, G_loss: -0.0003\n",
      "Epoch [32/100], Batch [100], D_loss: 1.0282, D_adv: 1.0005, D_rec: 0.0028, G_loss: -0.0003\n",
      "Epoch [33/100], Batch [0], D_loss: 1.0273, D_adv: 1.0005, D_rec: 0.0027, G_loss: -0.0003\n",
      "Epoch [33/100], Batch [100], D_loss: 1.0253, D_adv: 1.0010, D_rec: 0.0024, G_loss: -0.0003\n",
      "Epoch [34/100], Batch [0], D_loss: 1.0317, D_adv: 1.0006, D_rec: 0.0031, G_loss: -0.0002\n",
      "Epoch [34/100], Batch [100], D_loss: 1.0236, D_adv: 1.0004, D_rec: 0.0023, G_loss: -0.0002\n",
      "Epoch [35/100], Batch [0], D_loss: 1.0241, D_adv: 1.0003, D_rec: 0.0024, G_loss: -0.0002\n",
      "Epoch [35/100], Batch [100], D_loss: 1.0340, D_adv: 1.0006, D_rec: 0.0033, G_loss: -0.0002\n",
      "Epoch [36/100], Batch [0], D_loss: 1.0268, D_adv: 1.0005, D_rec: 0.0026, G_loss: -0.0002\n",
      "Epoch [36/100], Batch [100], D_loss: 1.0447, D_adv: 1.0003, D_rec: 0.0044, G_loss: -0.0002\n",
      "Epoch [37/100], Batch [0], D_loss: 1.0233, D_adv: 1.0004, D_rec: 0.0023, G_loss: -0.0002\n",
      "Epoch [37/100], Batch [100], D_loss: 1.0286, D_adv: 1.0004, D_rec: 0.0028, G_loss: -0.0002\n",
      "Epoch [38/100], Batch [0], D_loss: 1.0305, D_adv: 1.0005, D_rec: 0.0030, G_loss: -0.0002\n",
      "Epoch [38/100], Batch [100], D_loss: 1.0214, D_adv: 1.0004, D_rec: 0.0021, G_loss: -0.0002\n",
      "Epoch [39/100], Batch [0], D_loss: 1.0356, D_adv: 1.0004, D_rec: 0.0035, G_loss: -0.0002\n",
      "Epoch [39/100], Batch [100], D_loss: 1.0252, D_adv: 1.0004, D_rec: 0.0025, G_loss: -0.0002\n",
      "Epoch [40/100], Batch [0], D_loss: 1.0313, D_adv: 1.0005, D_rec: 0.0031, G_loss: -0.0002\n",
      "Epoch [40/100], Batch [100], D_loss: 1.0217, D_adv: 1.0002, D_rec: 0.0021, G_loss: -0.0002\n",
      "Epoch [41/100], Batch [0], D_loss: 1.0309, D_adv: 1.0003, D_rec: 0.0031, G_loss: -0.0001\n",
      "Epoch [41/100], Batch [100], D_loss: 1.0292, D_adv: 1.0004, D_rec: 0.0029, G_loss: -0.0002\n",
      "Epoch [42/100], Batch [0], D_loss: 1.0236, D_adv: 1.0004, D_rec: 0.0023, G_loss: -0.0001\n",
      "Epoch [42/100], Batch [100], D_loss: 1.0278, D_adv: 1.0005, D_rec: 0.0027, G_loss: -0.0002\n",
      "Epoch [43/100], Batch [0], D_loss: 1.0348, D_adv: 1.0003, D_rec: 0.0034, G_loss: -0.0001\n",
      "Epoch [43/100], Batch [100], D_loss: 1.0198, D_adv: 1.0004, D_rec: 0.0019, G_loss: -0.0002\n",
      "Epoch [44/100], Batch [0], D_loss: 1.0262, D_adv: 1.0003, D_rec: 0.0026, G_loss: -0.0002\n",
      "Epoch [44/100], Batch [100], D_loss: 1.0247, D_adv: 1.0002, D_rec: 0.0024, G_loss: -0.0001\n",
      "Epoch [45/100], Batch [0], D_loss: 1.0197, D_adv: 1.0002, D_rec: 0.0020, G_loss: -0.0002\n",
      "Epoch [45/100], Batch [100], D_loss: 1.0288, D_adv: 1.0003, D_rec: 0.0028, G_loss: -0.0001\n",
      "Epoch [46/100], Batch [0], D_loss: 1.0233, D_adv: 1.0004, D_rec: 0.0023, G_loss: -0.0001\n",
      "Epoch [46/100], Batch [100], D_loss: 1.0243, D_adv: 1.0002, D_rec: 0.0024, G_loss: -0.0001\n",
      "Epoch [47/100], Batch [0], D_loss: 1.0233, D_adv: 1.0003, D_rec: 0.0023, G_loss: -0.0001\n",
      "Epoch [47/100], Batch [100], D_loss: 1.0358, D_adv: 1.0008, D_rec: 0.0035, G_loss: -0.0002\n",
      "Epoch [48/100], Batch [0], D_loss: 1.0205, D_adv: 1.0003, D_rec: 0.0020, G_loss: -0.0002\n",
      "Epoch [48/100], Batch [100], D_loss: 1.0203, D_adv: 1.0004, D_rec: 0.0020, G_loss: -0.0002\n",
      "Epoch [49/100], Batch [0], D_loss: 1.0199, D_adv: 1.0003, D_rec: 0.0020, G_loss: -0.0002\n",
      "Epoch [49/100], Batch [100], D_loss: 1.0372, D_adv: 1.0123, D_rec: 0.0025, G_loss: -0.0257\n",
      "Epoch [50/100], Batch [0], D_loss: 1.3377, D_adv: 1.3056, D_rec: 0.0032, G_loss: -0.0781\n",
      "Epoch [50/100], Batch [100], D_loss: 1.0254, D_adv: 1.0006, D_rec: 0.0025, G_loss: -0.0003\n",
      "Epoch [51/100], Batch [0], D_loss: 1.0275, D_adv: 1.0006, D_rec: 0.0027, G_loss: -0.0004\n",
      "Epoch [51/100], Batch [100], D_loss: 1.0393, D_adv: 1.0024, D_rec: 0.0037, G_loss: -0.0009\n",
      "Epoch [52/100], Batch [0], D_loss: 1.0322, D_adv: 1.0007, D_rec: 0.0032, G_loss: -0.0004\n",
      "Epoch [52/100], Batch [100], D_loss: 1.0199, D_adv: 1.0003, D_rec: 0.0020, G_loss: -0.0002\n",
      "Epoch [53/100], Batch [0], D_loss: 1.0574, D_adv: 1.0007, D_rec: 0.0057, G_loss: -0.0002\n",
      "Epoch [53/100], Batch [100], D_loss: 1.0206, D_adv: 1.0002, D_rec: 0.0020, G_loss: -0.0002\n",
      "Epoch [54/100], Batch [0], D_loss: 1.0290, D_adv: 1.0003, D_rec: 0.0029, G_loss: -0.0001\n",
      "Epoch [54/100], Batch [100], D_loss: 1.0278, D_adv: 1.0004, D_rec: 0.0027, G_loss: -0.0003\n",
      "Epoch [55/100], Batch [0], D_loss: 1.0272, D_adv: 1.0008, D_rec: 0.0026, G_loss: -0.0003\n",
      "Epoch [55/100], Batch [100], D_loss: 1.0253, D_adv: 1.0004, D_rec: 0.0025, G_loss: -0.0002\n",
      "Epoch [56/100], Batch [0], D_loss: 1.0295, D_adv: 1.0005, D_rec: 0.0029, G_loss: -0.0003\n",
      "Epoch [56/100], Batch [100], D_loss: 1.0231, D_adv: 1.0011, D_rec: 0.0022, G_loss: -0.0009\n",
      "Epoch [57/100], Batch [0], D_loss: 1.5236, D_adv: 1.4751, D_rec: 0.0049, G_loss: -0.0416\n",
      "Epoch [57/100], Batch [100], D_loss: 1.0389, D_adv: 1.0014, D_rec: 0.0037, G_loss: -0.0006\n",
      "Epoch [58/100], Batch [0], D_loss: 1.0327, D_adv: 1.0010, D_rec: 0.0032, G_loss: -0.0007\n",
      "Epoch [58/100], Batch [100], D_loss: 1.0245, D_adv: 1.0012, D_rec: 0.0023, G_loss: -0.0005\n",
      "Epoch [59/100], Batch [0], D_loss: 1.9358, D_adv: 1.8658, D_rec: 0.0070, G_loss: -0.1392\n",
      "Epoch [59/100], Batch [100], D_loss: 1.0299, D_adv: 1.0013, D_rec: 0.0029, G_loss: -0.0003\n",
      "Epoch [60/100], Batch [0], D_loss: 1.9925, D_adv: 1.9647, D_rec: 0.0028, G_loss: -0.0356\n",
      "Epoch [60/100], Batch [100], D_loss: 1.0203, D_adv: 1.0005, D_rec: 0.0020, G_loss: -0.0002\n",
      "Epoch [61/100], Batch [0], D_loss: 1.0254, D_adv: 1.0007, D_rec: 0.0025, G_loss: -0.0003\n",
      "Epoch [61/100], Batch [100], D_loss: 1.0199, D_adv: 1.0004, D_rec: 0.0020, G_loss: -0.0002\n",
      "Epoch [62/100], Batch [0], D_loss: 1.0252, D_adv: 1.0003, D_rec: 0.0025, G_loss: -0.0002\n",
      "Epoch [62/100], Batch [100], D_loss: 1.0307, D_adv: 1.0004, D_rec: 0.0030, G_loss: -0.0002\n",
      "Epoch [63/100], Batch [0], D_loss: 1.0254, D_adv: 1.0003, D_rec: 0.0025, G_loss: -0.0001\n",
      "Epoch [63/100], Batch [100], D_loss: 1.0217, D_adv: 1.0002, D_rec: 0.0022, G_loss: -0.0001\n",
      "Epoch [64/100], Batch [0], D_loss: 1.0209, D_adv: 1.0002, D_rec: 0.0021, G_loss: -0.0001\n",
      "Epoch [64/100], Batch [100], D_loss: 1.0222, D_adv: 1.0002, D_rec: 0.0022, G_loss: -0.0001\n",
      "Epoch [65/100], Batch [0], D_loss: 1.0353, D_adv: 1.0001, D_rec: 0.0035, G_loss: -0.0000\n",
      "Epoch [65/100], Batch [100], D_loss: 1.0209, D_adv: 1.0002, D_rec: 0.0021, G_loss: -0.0001\n",
      "Epoch [66/100], Batch [0], D_loss: 1.0211, D_adv: 1.0002, D_rec: 0.0021, G_loss: -0.0001\n",
      "Epoch [66/100], Batch [100], D_loss: 1.0161, D_adv: 1.0002, D_rec: 0.0016, G_loss: -0.0001\n",
      "Epoch [67/100], Batch [0], D_loss: 1.0211, D_adv: 1.0002, D_rec: 0.0021, G_loss: -0.0001\n",
      "Epoch [67/100], Batch [100], D_loss: 1.0277, D_adv: 1.0001, D_rec: 0.0028, G_loss: -0.0000\n",
      "Epoch [68/100], Batch [0], D_loss: 1.0255, D_adv: 1.0002, D_rec: 0.0025, G_loss: -0.0001\n",
      "Epoch [68/100], Batch [100], D_loss: 1.0154, D_adv: 1.0001, D_rec: 0.0015, G_loss: -0.0001\n",
      "Epoch [69/100], Batch [0], D_loss: 1.0376, D_adv: 1.0002, D_rec: 0.0037, G_loss: -0.0001\n",
      "Epoch [69/100], Batch [100], D_loss: 1.0316, D_adv: 1.0001, D_rec: 0.0031, G_loss: -0.0001\n",
      "Epoch [70/100], Batch [0], D_loss: 1.0192, D_adv: 1.0001, D_rec: 0.0019, G_loss: -0.0001\n",
      "Epoch [70/100], Batch [100], D_loss: 1.0220, D_adv: 1.0001, D_rec: 0.0022, G_loss: -0.0001\n",
      "Epoch [71/100], Batch [0], D_loss: 1.0212, D_adv: 1.0001, D_rec: 0.0021, G_loss: -0.0001\n",
      "Epoch [71/100], Batch [100], D_loss: 1.0158, D_adv: 1.0001, D_rec: 0.0016, G_loss: -0.0001\n",
      "Epoch [72/100], Batch [0], D_loss: 1.0187, D_adv: 1.0001, D_rec: 0.0019, G_loss: -0.0001\n",
      "Epoch [72/100], Batch [100], D_loss: 1.0201, D_adv: 1.0001, D_rec: 0.0020, G_loss: -0.0001\n",
      "Epoch [73/100], Batch [0], D_loss: 1.0277, D_adv: 1.0002, D_rec: 0.0028, G_loss: -0.0001\n",
      "Epoch [73/100], Batch [100], D_loss: 1.0252, D_adv: 1.0001, D_rec: 0.0025, G_loss: -0.0001\n",
      "Epoch [74/100], Batch [0], D_loss: 1.0195, D_adv: 1.0001, D_rec: 0.0019, G_loss: -0.0001\n",
      "Epoch [74/100], Batch [100], D_loss: 1.0205, D_adv: 1.0002, D_rec: 0.0020, G_loss: -0.0001\n",
      "Epoch [75/100], Batch [0], D_loss: 1.0235, D_adv: 1.0001, D_rec: 0.0023, G_loss: -0.0001\n",
      "Epoch [75/100], Batch [100], D_loss: 1.0223, D_adv: 1.0001, D_rec: 0.0022, G_loss: -0.0001\n",
      "Epoch [76/100], Batch [0], D_loss: 1.0384, D_adv: 1.0001, D_rec: 0.0038, G_loss: -0.0001\n",
      "Epoch [76/100], Batch [100], D_loss: 1.0144, D_adv: 1.0001, D_rec: 0.0014, G_loss: -0.0001\n",
      "Epoch [77/100], Batch [0], D_loss: 1.0190, D_adv: 1.0001, D_rec: 0.0019, G_loss: -0.0001\n",
      "Epoch [77/100], Batch [100], D_loss: 1.0310, D_adv: 1.0003, D_rec: 0.0031, G_loss: -0.0001\n",
      "Epoch [78/100], Batch [0], D_loss: 1.0188, D_adv: 1.0001, D_rec: 0.0019, G_loss: -0.0001\n",
      "Epoch [78/100], Batch [100], D_loss: 1.0243, D_adv: 1.0004, D_rec: 0.0024, G_loss: -0.0001\n",
      "Epoch [79/100], Batch [0], D_loss: 1.0168, D_adv: 1.0001, D_rec: 0.0017, G_loss: -0.0001\n",
      "Epoch [79/100], Batch [100], D_loss: 1.0172, D_adv: 1.0001, D_rec: 0.0017, G_loss: -0.0001\n",
      "Epoch [80/100], Batch [0], D_loss: 1.0180, D_adv: 1.0001, D_rec: 0.0018, G_loss: -0.0001\n",
      "Epoch [80/100], Batch [100], D_loss: 1.0213, D_adv: 1.0001, D_rec: 0.0021, G_loss: -0.0001\n",
      "Epoch [81/100], Batch [0], D_loss: 1.0226, D_adv: 1.0001, D_rec: 0.0023, G_loss: -0.0001\n",
      "Epoch [81/100], Batch [100], D_loss: 1.0145, D_adv: 1.0001, D_rec: 0.0014, G_loss: -0.0001\n",
      "Epoch [82/100], Batch [0], D_loss: 1.0289, D_adv: 1.0002, D_rec: 0.0029, G_loss: -0.0001\n",
      "Epoch [82/100], Batch [100], D_loss: 2.0522, D_adv: 1.9997, D_rec: 0.0053, G_loss: -0.9959\n",
      "Epoch [83/100], Batch [0], D_loss: 2.0260, D_adv: 2.0004, D_rec: 0.0026, G_loss: -0.9997\n",
      "Epoch [83/100], Batch [100], D_loss: 2.0179, D_adv: 1.9995, D_rec: 0.0018, G_loss: -0.9992\n",
      "Epoch [84/100], Batch [0], D_loss: 1.9763, D_adv: 1.9546, D_rec: 0.0022, G_loss: -0.3172\n",
      "Epoch [84/100], Batch [100], D_loss: 1.9180, D_adv: 1.8795, D_rec: 0.0039, G_loss: -0.4905\n",
      "Epoch [85/100], Batch [0], D_loss: 2.0377, D_adv: 2.0053, D_rec: 0.0032, G_loss: -0.9979\n",
      "Epoch [85/100], Batch [100], D_loss: 2.0054, D_adv: 1.9744, D_rec: 0.0031, G_loss: -0.8410\n",
      "Epoch [86/100], Batch [0], D_loss: 1.5138, D_adv: 1.4701, D_rec: 0.0044, G_loss: -0.3034\n",
      "Epoch [86/100], Batch [100], D_loss: 2.0931, D_adv: 2.0633, D_rec: 0.0030, G_loss: -0.2670\n",
      "Epoch [87/100], Batch [0], D_loss: 1.8403, D_adv: 1.8046, D_rec: 0.0036, G_loss: -0.4867\n",
      "Epoch [87/100], Batch [100], D_loss: 1.8833, D_adv: 1.8533, D_rec: 0.0030, G_loss: -0.6572\n",
      "Epoch [88/100], Batch [0], D_loss: 1.6655, D_adv: 1.6389, D_rec: 0.0027, G_loss: -0.5685\n",
      "Epoch [88/100], Batch [100], D_loss: 1.9824, D_adv: 1.9579, D_rec: 0.0024, G_loss: -0.8268\n",
      "Epoch [89/100], Batch [0], D_loss: 1.8906, D_adv: 1.8568, D_rec: 0.0034, G_loss: -0.1996\n",
      "Epoch [89/100], Batch [100], D_loss: 1.6904, D_adv: 1.6637, D_rec: 0.0027, G_loss: -0.3816\n",
      "Epoch [90/100], Batch [0], D_loss: 1.7352, D_adv: 1.7017, D_rec: 0.0033, G_loss: -0.4207\n",
      "Epoch [90/100], Batch [100], D_loss: 1.0183, D_adv: 1.0014, D_rec: 0.0017, G_loss: -0.0010\n",
      "Epoch [91/100], Batch [0], D_loss: 1.9649, D_adv: 1.9334, D_rec: 0.0032, G_loss: -0.0631\n",
      "Epoch [91/100], Batch [100], D_loss: 1.6754, D_adv: 1.6545, D_rec: 0.0021, G_loss: -0.3818\n",
      "Epoch [92/100], Batch [0], D_loss: 1.7105, D_adv: 1.6838, D_rec: 0.0027, G_loss: -0.3722\n",
      "Epoch [92/100], Batch [100], D_loss: 1.0425, D_adv: 1.0172, D_rec: 0.0025, G_loss: -0.0008\n",
      "Epoch [93/100], Batch [0], D_loss: 1.0391, D_adv: 1.0119, D_rec: 0.0027, G_loss: -0.0021\n",
      "Epoch [93/100], Batch [100], D_loss: 1.7884, D_adv: 1.7661, D_rec: 0.0022, G_loss: -0.6472\n",
      "Epoch [94/100], Batch [0], D_loss: 1.7381, D_adv: 1.7083, D_rec: 0.0030, G_loss: -0.3371\n",
      "Epoch [94/100], Batch [100], D_loss: 1.5074, D_adv: 1.4795, D_rec: 0.0028, G_loss: -0.3492\n",
      "Epoch [95/100], Batch [0], D_loss: 1.9002, D_adv: 1.8683, D_rec: 0.0032, G_loss: -0.5293\n",
      "Epoch [95/100], Batch [100], D_loss: 1.9025, D_adv: 1.8647, D_rec: 0.0038, G_loss: -0.6268\n",
      "Epoch [96/100], Batch [0], D_loss: 1.7347, D_adv: 1.7132, D_rec: 0.0021, G_loss: -0.5211\n",
      "Epoch [96/100], Batch [100], D_loss: 1.2258, D_adv: 1.1906, D_rec: 0.0035, G_loss: -0.0465\n",
      "Epoch [97/100], Batch [0], D_loss: 1.0218, D_adv: 1.0021, D_rec: 0.0020, G_loss: -0.0013\n",
      "Epoch [97/100], Batch [100], D_loss: 1.0300, D_adv: 1.0009, D_rec: 0.0029, G_loss: -0.0007\n",
      "Epoch [98/100], Batch [0], D_loss: 1.0250, D_adv: 1.0012, D_rec: 0.0024, G_loss: -0.0009\n",
      "Epoch [98/100], Batch [100], D_loss: 1.0393, D_adv: 1.0205, D_rec: 0.0019, G_loss: -0.0030\n",
      "Epoch [99/100], Batch [0], D_loss: 1.9255, D_adv: 1.8910, D_rec: 0.0035, G_loss: -0.0286\n",
      "Epoch [99/100], Batch [100], D_loss: 1.0213, D_adv: 1.0003, D_rec: 0.0021, G_loss: -0.0001\n",
      "Generating synthetic images...\n",
      "Class 0: Generated 21/1000 images\n",
      "Class 0: Generated 37/1000 images\n",
      "Class 0: Generated 49/1000 images\n",
      "Class 0: Generated 62/1000 images\n",
      "Class 0: Generated 78/1000 images\n",
      "Class 0: Generated 93/1000 images\n",
      "Class 0: Generated 108/1000 images\n",
      "Class 0: Generated 121/1000 images\n",
      "Class 0: Generated 137/1000 images\n",
      "Class 0: Generated 146/1000 images\n",
      "Class 0: Generated 164/1000 images\n",
      "Class 0: Generated 180/1000 images\n",
      "Class 0: Generated 201/1000 images\n",
      "Class 0: Generated 216/1000 images\n",
      "Class 0: Generated 236/1000 images\n",
      "Class 0: Generated 250/1000 images\n",
      "Class 0: Generated 263/1000 images\n",
      "Class 0: Generated 275/1000 images\n",
      "Class 0: Generated 289/1000 images\n",
      "Class 0: Generated 305/1000 images\n",
      "Class 0: Generated 321/1000 images\n",
      "Class 0: Generated 337/1000 images\n",
      "Class 0: Generated 359/1000 images\n",
      "Class 0: Generated 373/1000 images\n",
      "Class 0: Generated 387/1000 images\n",
      "Class 0: Generated 410/1000 images\n",
      "Class 0: Generated 422/1000 images\n",
      "Class 0: Generated 444/1000 images\n",
      "Class 0: Generated 461/1000 images\n",
      "Class 0: Generated 476/1000 images\n",
      "Class 0: Generated 489/1000 images\n",
      "Class 0: Generated 506/1000 images\n",
      "Class 0: Generated 523/1000 images\n",
      "Class 0: Generated 542/1000 images\n",
      "Class 0: Generated 556/1000 images\n",
      "Class 0: Generated 574/1000 images\n",
      "Class 0: Generated 592/1000 images\n",
      "Class 0: Generated 607/1000 images\n",
      "Class 0: Generated 621/1000 images\n",
      "Class 0: Generated 635/1000 images\n",
      "Class 0: Generated 647/1000 images\n",
      "Class 0: Generated 662/1000 images\n",
      "Class 0: Generated 681/1000 images\n",
      "Class 0: Generated 703/1000 images\n",
      "Class 0: Generated 720/1000 images\n",
      "Class 0: Generated 734/1000 images\n",
      "Class 0: Generated 749/1000 images\n",
      "Class 0: Generated 768/1000 images\n",
      "Class 0: Generated 784/1000 images\n",
      "Class 0: Generated 800/1000 images\n",
      "Class 0: Generated 816/1000 images\n",
      "Class 0: Generated 829/1000 images\n",
      "Class 0: Generated 847/1000 images\n",
      "Class 0: Generated 866/1000 images\n",
      "Class 0: Generated 882/1000 images\n",
      "Class 0: Generated 899/1000 images\n",
      "Class 0: Generated 916/1000 images\n",
      "Class 0: Generated 932/1000 images\n",
      "Class 0: Generated 947/1000 images\n",
      "Class 0: Generated 969/1000 images\n",
      "Class 0: Generated 986/1000 images\n",
      "Class 0: Generated 1000/1000 images\n",
      "Class 1: Generated 10/1000 images\n",
      "Class 1: Generated 30/1000 images\n",
      "Class 1: Generated 47/1000 images\n",
      "Class 1: Generated 62/1000 images\n",
      "Class 1: Generated 79/1000 images\n",
      "Class 1: Generated 93/1000 images\n",
      "Class 1: Generated 105/1000 images\n",
      "Class 1: Generated 123/1000 images\n",
      "Class 1: Generated 144/1000 images\n",
      "Class 1: Generated 156/1000 images\n",
      "Class 1: Generated 172/1000 images\n",
      "Class 1: Generated 187/1000 images\n",
      "Class 1: Generated 206/1000 images\n",
      "Class 1: Generated 216/1000 images\n",
      "Class 1: Generated 229/1000 images\n",
      "Class 1: Generated 245/1000 images\n",
      "Class 1: Generated 260/1000 images\n",
      "Class 1: Generated 277/1000 images\n",
      "Class 1: Generated 295/1000 images\n",
      "Class 1: Generated 312/1000 images\n",
      "Class 1: Generated 328/1000 images\n",
      "Class 1: Generated 347/1000 images\n",
      "Class 1: Generated 367/1000 images\n",
      "Class 1: Generated 381/1000 images\n",
      "Class 1: Generated 402/1000 images\n",
      "Class 1: Generated 417/1000 images\n",
      "Class 1: Generated 429/1000 images\n",
      "Class 1: Generated 441/1000 images\n",
      "Class 1: Generated 458/1000 images\n",
      "Class 1: Generated 473/1000 images\n",
      "Class 1: Generated 485/1000 images\n",
      "Class 1: Generated 500/1000 images\n",
      "Class 1: Generated 511/1000 images\n",
      "Class 1: Generated 523/1000 images\n",
      "Class 1: Generated 535/1000 images\n",
      "Class 1: Generated 550/1000 images\n",
      "Class 1: Generated 565/1000 images\n",
      "Class 1: Generated 581/1000 images\n",
      "Class 1: Generated 599/1000 images\n",
      "Class 1: Generated 615/1000 images\n",
      "Class 1: Generated 634/1000 images\n",
      "Class 1: Generated 649/1000 images\n",
      "Class 1: Generated 662/1000 images\n",
      "Class 1: Generated 680/1000 images\n",
      "Class 1: Generated 694/1000 images\n",
      "Class 1: Generated 708/1000 images\n",
      "Class 1: Generated 727/1000 images\n",
      "Class 1: Generated 746/1000 images\n",
      "Class 1: Generated 763/1000 images\n",
      "Class 1: Generated 780/1000 images\n",
      "Class 1: Generated 795/1000 images\n",
      "Class 1: Generated 810/1000 images\n",
      "Class 1: Generated 824/1000 images\n",
      "Class 1: Generated 840/1000 images\n",
      "Class 1: Generated 856/1000 images\n",
      "Class 1: Generated 876/1000 images\n",
      "Class 1: Generated 890/1000 images\n",
      "Class 1: Generated 903/1000 images\n",
      "Class 1: Generated 919/1000 images\n",
      "Class 1: Generated 939/1000 images\n",
      "Class 1: Generated 953/1000 images\n",
      "Class 1: Generated 964/1000 images\n",
      "Class 1: Generated 980/1000 images\n",
      "Class 1: Generated 995/1000 images\n",
      "Class 1: Generated 1000/1000 images\n",
      "Class 2: Generated 13/1000 images\n",
      "Class 2: Generated 22/1000 images\n",
      "Class 2: Generated 43/1000 images\n",
      "Class 2: Generated 52/1000 images\n",
      "Class 2: Generated 67/1000 images\n",
      "Class 2: Generated 83/1000 images\n",
      "Class 2: Generated 97/1000 images\n",
      "Class 2: Generated 117/1000 images\n",
      "Class 2: Generated 134/1000 images\n",
      "Class 2: Generated 148/1000 images\n",
      "Class 2: Generated 170/1000 images\n",
      "Class 2: Generated 184/1000 images\n",
      "Class 2: Generated 197/1000 images\n",
      "Class 2: Generated 209/1000 images\n",
      "Class 2: Generated 223/1000 images\n",
      "Class 2: Generated 240/1000 images\n",
      "Class 2: Generated 257/1000 images\n",
      "Class 2: Generated 273/1000 images\n",
      "Class 2: Generated 285/1000 images\n",
      "Class 2: Generated 302/1000 images\n",
      "Class 2: Generated 315/1000 images\n",
      "Class 2: Generated 326/1000 images\n",
      "Class 2: Generated 345/1000 images\n",
      "Class 2: Generated 363/1000 images\n",
      "Class 2: Generated 382/1000 images\n",
      "Class 2: Generated 401/1000 images\n",
      "Class 2: Generated 417/1000 images\n",
      "Class 2: Generated 433/1000 images\n",
      "Class 2: Generated 447/1000 images\n",
      "Class 2: Generated 463/1000 images\n",
      "Class 2: Generated 476/1000 images\n",
      "Class 2: Generated 493/1000 images\n",
      "Class 2: Generated 505/1000 images\n",
      "Class 2: Generated 522/1000 images\n",
      "Class 2: Generated 537/1000 images\n",
      "Class 2: Generated 556/1000 images\n",
      "Class 2: Generated 570/1000 images\n",
      "Class 2: Generated 587/1000 images\n",
      "Class 2: Generated 598/1000 images\n",
      "Class 2: Generated 610/1000 images\n",
      "Class 2: Generated 623/1000 images\n",
      "Class 2: Generated 643/1000 images\n",
      "Class 2: Generated 655/1000 images\n",
      "Class 2: Generated 667/1000 images\n",
      "Class 2: Generated 681/1000 images\n",
      "Class 2: Generated 693/1000 images\n",
      "Class 2: Generated 710/1000 images\n",
      "Class 2: Generated 726/1000 images\n",
      "Class 2: Generated 740/1000 images\n",
      "Class 2: Generated 757/1000 images\n",
      "Class 2: Generated 767/1000 images\n",
      "Class 2: Generated 783/1000 images\n",
      "Class 2: Generated 799/1000 images\n",
      "Class 2: Generated 813/1000 images\n",
      "Class 2: Generated 827/1000 images\n",
      "Class 2: Generated 845/1000 images\n",
      "Class 2: Generated 862/1000 images\n",
      "Class 2: Generated 881/1000 images\n",
      "Class 2: Generated 891/1000 images\n",
      "Class 2: Generated 909/1000 images\n",
      "Class 2: Generated 923/1000 images\n",
      "Class 2: Generated 940/1000 images\n",
      "Class 2: Generated 956/1000 images\n",
      "Class 2: Generated 974/1000 images\n",
      "Class 2: Generated 988/1000 images\n",
      "Class 2: Generated 1000/1000 images\n",
      "Class 3: Generated 15/1000 images\n",
      "Class 3: Generated 27/1000 images\n",
      "Class 3: Generated 43/1000 images\n",
      "Class 3: Generated 62/1000 images\n",
      "Class 3: Generated 79/1000 images\n",
      "Class 3: Generated 97/1000 images\n",
      "Class 3: Generated 111/1000 images\n",
      "Class 3: Generated 128/1000 images\n",
      "Class 3: Generated 148/1000 images\n",
      "Class 3: Generated 166/1000 images\n",
      "Class 3: Generated 183/1000 images\n",
      "Class 3: Generated 197/1000 images\n",
      "Class 3: Generated 211/1000 images\n",
      "Class 3: Generated 227/1000 images\n",
      "Class 3: Generated 245/1000 images\n",
      "Class 3: Generated 261/1000 images\n",
      "Class 3: Generated 272/1000 images\n",
      "Class 3: Generated 285/1000 images\n",
      "Class 3: Generated 296/1000 images\n",
      "Class 3: Generated 311/1000 images\n",
      "Class 3: Generated 328/1000 images\n",
      "Class 3: Generated 347/1000 images\n",
      "Class 3: Generated 364/1000 images\n",
      "Class 3: Generated 375/1000 images\n",
      "Class 3: Generated 389/1000 images\n",
      "Class 3: Generated 402/1000 images\n",
      "Class 3: Generated 421/1000 images\n",
      "Class 3: Generated 434/1000 images\n",
      "Class 3: Generated 446/1000 images\n",
      "Class 3: Generated 461/1000 images\n",
      "Class 3: Generated 476/1000 images\n",
      "Class 3: Generated 495/1000 images\n",
      "Class 3: Generated 518/1000 images\n",
      "Class 3: Generated 533/1000 images\n",
      "Class 3: Generated 552/1000 images\n",
      "Class 3: Generated 569/1000 images\n",
      "Class 3: Generated 582/1000 images\n",
      "Class 3: Generated 599/1000 images\n",
      "Class 3: Generated 607/1000 images\n",
      "Class 3: Generated 631/1000 images\n",
      "Class 3: Generated 644/1000 images\n",
      "Class 3: Generated 659/1000 images\n",
      "Class 3: Generated 671/1000 images\n",
      "Class 3: Generated 686/1000 images\n",
      "Class 3: Generated 695/1000 images\n",
      "Class 3: Generated 710/1000 images\n",
      "Class 3: Generated 725/1000 images\n",
      "Class 3: Generated 737/1000 images\n",
      "Class 3: Generated 752/1000 images\n",
      "Class 3: Generated 769/1000 images\n",
      "Class 3: Generated 788/1000 images\n",
      "Class 3: Generated 806/1000 images\n",
      "Class 3: Generated 827/1000 images\n",
      "Class 3: Generated 843/1000 images\n",
      "Class 3: Generated 863/1000 images\n",
      "Class 3: Generated 873/1000 images\n",
      "Class 3: Generated 889/1000 images\n",
      "Class 3: Generated 904/1000 images\n",
      "Class 3: Generated 919/1000 images\n",
      "Class 3: Generated 929/1000 images\n",
      "Class 3: Generated 945/1000 images\n",
      "Class 3: Generated 958/1000 images\n",
      "Class 3: Generated 973/1000 images\n",
      "Class 3: Generated 984/1000 images\n",
      "Class 3: Generated 999/1000 images\n",
      "Class 3: Generated 1000/1000 images\n",
      "Class 4: Generated 15/1000 images\n",
      "Class 4: Generated 31/1000 images\n",
      "Class 4: Generated 50/1000 images\n",
      "Class 4: Generated 64/1000 images\n",
      "Class 4: Generated 83/1000 images\n",
      "Class 4: Generated 104/1000 images\n",
      "Class 4: Generated 122/1000 images\n",
      "Class 4: Generated 134/1000 images\n",
      "Class 4: Generated 154/1000 images\n",
      "Class 4: Generated 171/1000 images\n",
      "Class 4: Generated 183/1000 images\n",
      "Class 4: Generated 199/1000 images\n",
      "Class 4: Generated 215/1000 images\n",
      "Class 4: Generated 228/1000 images\n",
      "Class 4: Generated 248/1000 images\n",
      "Class 4: Generated 261/1000 images\n",
      "Class 4: Generated 273/1000 images\n",
      "Class 4: Generated 293/1000 images\n",
      "Class 4: Generated 310/1000 images\n",
      "Class 4: Generated 324/1000 images\n",
      "Class 4: Generated 346/1000 images\n",
      "Class 4: Generated 358/1000 images\n",
      "Class 4: Generated 376/1000 images\n",
      "Class 4: Generated 395/1000 images\n",
      "Class 4: Generated 410/1000 images\n",
      "Class 4: Generated 430/1000 images\n",
      "Class 4: Generated 442/1000 images\n",
      "Class 4: Generated 453/1000 images\n",
      "Class 4: Generated 469/1000 images\n",
      "Class 4: Generated 483/1000 images\n",
      "Class 4: Generated 501/1000 images\n",
      "Class 4: Generated 518/1000 images\n",
      "Class 4: Generated 528/1000 images\n",
      "Class 4: Generated 548/1000 images\n",
      "Class 4: Generated 563/1000 images\n",
      "Class 4: Generated 576/1000 images\n",
      "Class 4: Generated 587/1000 images\n",
      "Class 4: Generated 604/1000 images\n",
      "Class 4: Generated 621/1000 images\n",
      "Class 4: Generated 639/1000 images\n",
      "Class 4: Generated 652/1000 images\n",
      "Class 4: Generated 672/1000 images\n",
      "Class 4: Generated 685/1000 images\n",
      "Class 4: Generated 700/1000 images\n",
      "Class 4: Generated 712/1000 images\n",
      "Class 4: Generated 735/1000 images\n",
      "Class 4: Generated 746/1000 images\n",
      "Class 4: Generated 760/1000 images\n",
      "Class 4: Generated 775/1000 images\n",
      "Class 4: Generated 787/1000 images\n",
      "Class 4: Generated 805/1000 images\n",
      "Class 4: Generated 822/1000 images\n",
      "Class 4: Generated 834/1000 images\n",
      "Class 4: Generated 848/1000 images\n",
      "Class 4: Generated 859/1000 images\n",
      "Class 4: Generated 878/1000 images\n",
      "Class 4: Generated 892/1000 images\n",
      "Class 4: Generated 907/1000 images\n",
      "Class 4: Generated 922/1000 images\n",
      "Class 4: Generated 937/1000 images\n",
      "Class 4: Generated 953/1000 images\n",
      "Class 4: Generated 968/1000 images\n",
      "Class 4: Generated 988/1000 images\n",
      "Class 4: Generated 1000/1000 images\n",
      "Class 5: Generated 18/1000 images\n",
      "Class 5: Generated 40/1000 images\n",
      "Class 5: Generated 54/1000 images\n",
      "Class 5: Generated 69/1000 images\n",
      "Class 5: Generated 87/1000 images\n",
      "Class 5: Generated 103/1000 images\n",
      "Class 5: Generated 119/1000 images\n",
      "Class 5: Generated 138/1000 images\n",
      "Class 5: Generated 157/1000 images\n",
      "Class 5: Generated 173/1000 images\n",
      "Class 5: Generated 188/1000 images\n",
      "Class 5: Generated 208/1000 images\n",
      "Class 5: Generated 223/1000 images\n",
      "Class 5: Generated 239/1000 images\n",
      "Class 5: Generated 255/1000 images\n",
      "Class 5: Generated 271/1000 images\n",
      "Class 5: Generated 287/1000 images\n",
      "Class 5: Generated 309/1000 images\n",
      "Class 5: Generated 326/1000 images\n",
      "Class 5: Generated 340/1000 images\n",
      "Class 5: Generated 356/1000 images\n",
      "Class 5: Generated 372/1000 images\n",
      "Class 5: Generated 388/1000 images\n",
      "Class 5: Generated 404/1000 images\n",
      "Class 5: Generated 420/1000 images\n",
      "Class 5: Generated 436/1000 images\n",
      "Class 5: Generated 450/1000 images\n",
      "Class 5: Generated 462/1000 images\n",
      "Class 5: Generated 474/1000 images\n",
      "Class 5: Generated 488/1000 images\n",
      "Class 5: Generated 505/1000 images\n",
      "Class 5: Generated 521/1000 images\n",
      "Class 5: Generated 533/1000 images\n",
      "Class 5: Generated 551/1000 images\n",
      "Class 5: Generated 567/1000 images\n",
      "Class 5: Generated 586/1000 images\n",
      "Class 5: Generated 602/1000 images\n",
      "Class 5: Generated 619/1000 images\n",
      "Class 5: Generated 636/1000 images\n",
      "Class 5: Generated 651/1000 images\n",
      "Class 5: Generated 665/1000 images\n",
      "Class 5: Generated 677/1000 images\n",
      "Class 5: Generated 685/1000 images\n",
      "Class 5: Generated 700/1000 images\n",
      "Class 5: Generated 719/1000 images\n",
      "Class 5: Generated 733/1000 images\n",
      "Class 5: Generated 750/1000 images\n",
      "Class 5: Generated 763/1000 images\n",
      "Class 5: Generated 779/1000 images\n",
      "Class 5: Generated 796/1000 images\n",
      "Class 5: Generated 815/1000 images\n",
      "Class 5: Generated 831/1000 images\n",
      "Class 5: Generated 845/1000 images\n",
      "Class 5: Generated 862/1000 images\n",
      "Class 5: Generated 877/1000 images\n",
      "Class 5: Generated 889/1000 images\n",
      "Class 5: Generated 901/1000 images\n",
      "Class 5: Generated 913/1000 images\n",
      "Class 5: Generated 930/1000 images\n",
      "Class 5: Generated 943/1000 images\n",
      "Class 5: Generated 955/1000 images\n",
      "Class 5: Generated 973/1000 images\n",
      "Class 5: Generated 988/1000 images\n",
      "Class 5: Generated 999/1000 images\n",
      "Class 5: Generated 1000/1000 images\n",
      "Class 6: Generated 14/1000 images\n",
      "Class 6: Generated 27/1000 images\n",
      "Class 6: Generated 39/1000 images\n",
      "Class 6: Generated 55/1000 images\n",
      "Class 6: Generated 74/1000 images\n",
      "Class 6: Generated 92/1000 images\n",
      "Class 6: Generated 108/1000 images\n",
      "Class 6: Generated 120/1000 images\n",
      "Class 6: Generated 134/1000 images\n",
      "Class 6: Generated 151/1000 images\n",
      "Class 6: Generated 170/1000 images\n",
      "Class 6: Generated 184/1000 images\n",
      "Class 6: Generated 194/1000 images\n",
      "Class 6: Generated 210/1000 images\n",
      "Class 6: Generated 226/1000 images\n",
      "Class 6: Generated 241/1000 images\n",
      "Class 6: Generated 257/1000 images\n",
      "Class 6: Generated 268/1000 images\n",
      "Class 6: Generated 286/1000 images\n",
      "Class 6: Generated 303/1000 images\n",
      "Class 6: Generated 325/1000 images\n",
      "Class 6: Generated 341/1000 images\n",
      "Class 6: Generated 360/1000 images\n",
      "Class 6: Generated 372/1000 images\n",
      "Class 6: Generated 389/1000 images\n",
      "Class 6: Generated 413/1000 images\n",
      "Class 6: Generated 433/1000 images\n",
      "Class 6: Generated 450/1000 images\n",
      "Class 6: Generated 474/1000 images\n",
      "Class 6: Generated 488/1000 images\n",
      "Class 6: Generated 507/1000 images\n",
      "Class 6: Generated 522/1000 images\n",
      "Class 6: Generated 537/1000 images\n",
      "Class 6: Generated 554/1000 images\n",
      "Class 6: Generated 571/1000 images\n",
      "Class 6: Generated 586/1000 images\n",
      "Class 6: Generated 603/1000 images\n",
      "Class 6: Generated 619/1000 images\n",
      "Class 6: Generated 638/1000 images\n",
      "Class 6: Generated 654/1000 images\n",
      "Class 6: Generated 669/1000 images\n",
      "Class 6: Generated 689/1000 images\n",
      "Class 6: Generated 703/1000 images\n",
      "Class 6: Generated 717/1000 images\n",
      "Class 6: Generated 725/1000 images\n",
      "Class 6: Generated 747/1000 images\n",
      "Class 6: Generated 766/1000 images\n",
      "Class 6: Generated 783/1000 images\n",
      "Class 6: Generated 798/1000 images\n",
      "Class 6: Generated 811/1000 images\n",
      "Class 6: Generated 824/1000 images\n",
      "Class 6: Generated 839/1000 images\n",
      "Class 6: Generated 854/1000 images\n",
      "Class 6: Generated 875/1000 images\n",
      "Class 6: Generated 888/1000 images\n",
      "Class 6: Generated 903/1000 images\n",
      "Class 6: Generated 912/1000 images\n",
      "Class 6: Generated 924/1000 images\n",
      "Class 6: Generated 944/1000 images\n",
      "Class 6: Generated 959/1000 images\n",
      "Class 6: Generated 975/1000 images\n",
      "Class 6: Generated 994/1000 images\n",
      "Class 6: Generated 1000/1000 images\n",
      "Training and generation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shutil\n",
    "\n",
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dirs, transform=None, device='cuda'):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dirs = img_dirs\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        \n",
    "        # Encode labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['encoded_label'] = self.label_encoder.fit_transform(self.data['dx'])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx]['image_id'] + '.jpg'\n",
    "        for img_dir in self.img_dirs:\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            if os.path.exists(img_path):\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                label = self.data.iloc[idx]['encoded_label']\n",
    "                return image, label\n",
    "        raise FileNotFoundError(f\"Image {img_name} not found in directories {self.img_dirs}\")\n",
    "\n",
    "class EnhancedSLEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EnhancedSLEBlock, self).__init__()\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Content branch - adjusted channel dimensions\n",
    "        self.content_fc1 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.content_fc2 = nn.Conv2d(out_channels, out_channels, 1)\n",
    "        \n",
    "        # Style branch\n",
    "        self.style_modulation = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 1),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x, skip_x):\n",
    "        # Content pathway\n",
    "        content = self.global_pool(x)\n",
    "        content = F.relu(self.content_fc1(content))\n",
    "        content = self.content_fc2(content)\n",
    "        content = torch.sigmoid(content)\n",
    "        \n",
    "        # Style pathway\n",
    "        style = self.style_modulation(skip_x)\n",
    "        \n",
    "        # Combine content and style\n",
    "        output = skip_x * content  # Content modulation\n",
    "        output = output + self.gamma * style + self.beta  # Style modulation\n",
    "        return output\n",
    "\n",
    "class EnhancedFASTGANGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=256, ngf=32, output_size=64):\n",
    "        super(EnhancedFASTGANGenerator, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.initial = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, 1, 0),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.sle1 = EnhancedSLEBlock(ngf * 8, ngf * 4)  # Changed input and output channels\n",
    "        self.sle2 = EnhancedSLEBlock(ngf * 4, ngf * 2)  # Changed input and output channels\n",
    "\n",
    "    def forward(self, z):\n",
    "        x0 = self.initial(z)\n",
    "        x1 = self.layer1(x0)\n",
    "        x1_sle = self.sle1(x0, x1)\n",
    "        x2 = self.layer2(x1_sle)\n",
    "        x2_sle = self.sle2(x1_sle, x2)\n",
    "        x3 = self.layer3(x2_sle)\n",
    "        x4 = self.layer4(x3)\n",
    "        return x4\n",
    "\n",
    "class EnhancedFASTGANDiscriminator(nn.Module):\n",
    "    def __init__(self, ndf=64, input_size=64):\n",
    "        super(EnhancedFASTGANDiscriminator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # Shared feature extractor\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # Discriminator head\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(ndf * 8, 1, 1),\n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Decoder for self-supervision\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ndf * 8, ndf * 4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ndf * 4, ndf * 2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ndf * 2, ndf, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ndf, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        validity = self.discriminator(features)\n",
    "        reconstruction = self.decoder(features)\n",
    "        return validity, reconstruction\n",
    "\n",
    "class SyntheticImageClassifier:\n",
    "    def __init__(self, num_classes, device='cuda'):\n",
    "        self.device = device\n",
    "        \n",
    "        # EfficientNetV2\n",
    "        self.efficientnet = models.efficientnet_v2_s(pretrained=True)\n",
    "        self.efficientnet.classifier[1] = nn.Linear(self.efficientnet.classifier[1].in_features, num_classes)\n",
    "        self.efficientnet = self.efficientnet.to(device)\n",
    "        \n",
    "        # ShuffleNetV2\n",
    "        self.shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "        self.shufflenet.fc = nn.Linear(self.shufflenet.fc.in_features, num_classes)\n",
    "        self.shufflenet = self.shufflenet.to(device)\n",
    "        \n",
    "        # Transformation for input images\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def classify_synthetic_images(self, synthetic_images):\n",
    "        resized_images = F.interpolate(synthetic_images, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        normalized_images = (resized_images - resized_images.min()) / (resized_images.max() - resized_images.min())\n",
    "        normalized_images = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(normalized_images)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            efficientnet_preds = self.efficientnet(normalized_images)\n",
    "            shufflenet_preds = self.shufflenet(normalized_images)\n",
    "        \n",
    "        efficientnet_classes = torch.argmax(efficientnet_preds, dim=1)\n",
    "        shufflenet_classes = torch.argmax(shufflenet_preds, dim=1)\n",
    "        \n",
    "        agreed_classification_mask = (efficientnet_classes == shufflenet_classes)\n",
    "        \n",
    "        return agreed_classification_mask\n",
    "\n",
    "def enhanced_train_step(real_imgs, generator, discriminator, g_optimizer, d_optimizer, \n",
    "                       device, lambda_rec=10.0):\n",
    "    batch_size = real_imgs.size(0)\n",
    "    \n",
    "    # Train Discriminator\n",
    "    d_optimizer.zero_grad()\n",
    "    \n",
    "    # Real images\n",
    "    real_validity, real_reconstruction = discriminator(real_imgs)\n",
    "    \n",
    "    # Generate fake images\n",
    "    z = torch.randn(batch_size, 256, 1, 1, device=device)\n",
    "    fake_imgs = generator(z)\n",
    "    fake_validity, _ = discriminator(fake_imgs.detach())\n",
    "    \n",
    "    # Hinge loss\n",
    "    d_loss_real = torch.mean(F.relu(1.0 - real_validity))\n",
    "    d_loss_fake = torch.mean(F.relu(1.0 + fake_validity))\n",
    "    d_loss_adv = d_loss_real + d_loss_fake\n",
    "    \n",
    "    # Reconstruction loss for self-supervision\n",
    "    d_loss_rec = F.mse_loss(real_reconstruction, real_imgs)\n",
    "    \n",
    "    # Total discriminator loss\n",
    "    d_loss = d_loss_adv + lambda_rec * d_loss_rec\n",
    "    \n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    # Train Generator\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    fake_validity, _ = discriminator(fake_imgs)\n",
    "    g_loss = -torch.mean(fake_validity)  # Hinge loss for generator\n",
    "    \n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return {\n",
    "        'd_loss': d_loss.item(),\n",
    "        'd_loss_adv': d_loss_adv.item(),\n",
    "        'd_loss_rec': d_loss_rec.item(),\n",
    "        'g_loss': g_loss.item()\n",
    "    }, fake_imgs\n",
    "\n",
    "def plot_data_distribution_comparison(original_csv, synthetic_images_dir):\n",
    "    metadata = pd.read_csv(original_csv)\n",
    "    original_class_counts = metadata['dx'].value_counts()\n",
    "    synthetic_class_counts = {}\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(metadata['dx'])\n",
    "    \n",
    "    for class_name in label_encoder.classes_:\n",
    "        class_dir = os.path.join(synthetic_images_dir, class_name)\n",
    "        if os.path.exists(class_dir):\n",
    "            synthetic_class_counts[class_name] = len([f for f in os.listdir(class_dir) \n",
    "                                                    if f.endswith(('.png', '.jpg'))])\n",
    "        else:\n",
    "            synthetic_class_counts[class_name] = 0\n",
    "    \n",
    "    synthetic_class_counts = pd.Series(synthetic_class_counts)\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    x = np.arange(len(original_class_counts))\n",
    "    width = 0.4\n",
    "    \n",
    "    plt.bar(x - width/2, original_class_counts.values, width, label='Original Dataset', color='blue', alpha=0.7)\n",
    "    plt.bar(x + width/2, synthetic_class_counts.values, width, label='Synthetic Images', color='orange', alpha=0.7)\n",
    "    \n",
    "    plt.title('Comparison of Original HAM10000 Dataset and Synthetic Images', fontsize=16)\n",
    "    plt.xlabel('Skin Lesion Type', fontsize=14)\n",
    "    plt.ylabel('Number of Samples', fontsize=14)\n",
    "    plt.xticks(x, original_class_counts.index, rotation=90, ha='right')\n",
    "    plt.legend()\n",
    "    \n",
    "    for i, (orig, synth) in enumerate(zip(original_class_counts.values, synthetic_class_counts.values)):\n",
    "        plt.text(i - width/2, orig + 50, str(int(orig)), ha='center', va='bottom', fontsize=8)\n",
    "        plt.text(i + width/2, synth + 50, str(int(synth)), ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('dataset_distribution_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "def copy_original_images_by_class(csv_file, img_dirs, output_base_dir='synthetic_images'):\n",
    "    metadata = pd.read_csv(csv_file)\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "    copied_images = set()\n",
    "    \n",
    "    for class_name in metadata['dx'].unique():\n",
    "        class_output_dir = os.path.join(output_base_dir, class_name)\n",
    "        os.makedirs(class_output_dir, exist_ok=True)\n",
    "        \n",
    "        class_metadata = metadata[metadata['dx'] == class_name]\n",
    "        \n",
    "        for _, row in class_metadata.iterrows():\n",
    "            img_filename = row['image_id'] + '.jpg'\n",
    "            \n",
    "            for img_dir in img_dirs:\n",
    "                img_path = os.path.join(img_dir, img_filename)\n",
    "                \n",
    "                if os.path.exists(img_path):\n",
    "                    dest_path = os.path.join(class_output_dir, img_filename)\n",
    "                    \n",
    "                    if img_path not in copied_images:\n",
    "                        shutil.copy2(img_path, dest_path)\n",
    "                        copied_images.add(img_path)\n",
    "                    break\n",
    "    \n",
    "    print(f\"Original images copied to {output_base_dir}\")\n",
    "    print(f\"Total unique images copied: {len(copied_images)}\")\n",
    "\n",
    "def train_enhanced_fastgan(generator, discriminator, dataloader, num_epochs, device='cuda', \n",
    "                          lambda_rec=10.0, save_interval=100):\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    os.makedirs('training_progress', exist_ok=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_imgs, _) in enumerate(dataloader):\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            \n",
    "            losses, fake_imgs = enhanced_train_step(\n",
    "                real_imgs, generator, discriminator,\n",
    "                g_optimizer, d_optimizer, device, lambda_rec\n",
    "            )\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch [{epoch}/{num_epochs}], Batch [{i}], '\n",
    "                      f'D_loss: {losses[\"d_loss\"]:.4f}, '\n",
    "                      f'D_adv: {losses[\"d_loss_adv\"]:.4f}, '\n",
    "                      f'D_rec: {losses[\"d_loss_rec\"]:.4f}, '\n",
    "                      f'G_loss: {losses[\"g_loss\"]:.4f}')\n",
    "                \n",
    "                # Save sample images\n",
    "                if i % save_interval == 0:\n",
    "                    save_image(fake_imgs[:16] * 0.5 + 0.5,\n",
    "                             f'training_progress/epoch_{epoch}_batch_{i}.png',\n",
    "                             nrow=4, normalize=False)\n",
    "    \n",
    "    return generator, discriminator\n",
    "\n",
    "def generate_synthetic_images(generator, classifier, num_classes, num_images_per_class,\n",
    "                            device='cuda', batch_size=64, output_dir='synthetic_images'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for class_idx in range(num_classes):\n",
    "            class_dir = os.path.join(output_dir, f'class_{class_idx}')\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "            \n",
    "            num_generated = 0\n",
    "            while num_generated < num_images_per_class:\n",
    "                # Generate images\n",
    "                z = torch.randn(batch_size, 256, 1, 1, device=device)\n",
    "                fake_imgs = generator(z)\n",
    "                \n",
    "                # Filter images using classifier\n",
    "                valid_mask = classifier.classify_synthetic_images(fake_imgs)\n",
    "                valid_images = fake_imgs[valid_mask]\n",
    "                \n",
    "                # Save valid images\n",
    "                for idx, img in enumerate(valid_images):\n",
    "                    if num_generated >= num_images_per_class:\n",
    "                        break\n",
    "                    save_image(img * 0.5 + 0.5,\n",
    "                             os.path.join(class_dir, f'synthetic_{num_generated}.png'))\n",
    "                    num_generated += 1\n",
    "                \n",
    "                print(f'Class {class_idx}: Generated {num_generated}/{num_images_per_class} images')\n",
    "\n",
    "def main():\n",
    "    # Set device and random seeds\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Dataset parameters\n",
    "    csv_file = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n",
    "    img_dirs = ['/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1', '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2']\n",
    "    \n",
    "    # Data preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # Initialize dataset and dataloader\n",
    "    dataset = HAM10000Dataset(csv_file, img_dirs, transform=transform, device=device)\n",
    "    num_classes = len(dataset.label_encoder.classes_)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(\"Class labels:\", dataset.label_encoder.classes_)\n",
    "    \n",
    "    batch_size = 64\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    # Initialize models\n",
    "    generator = EnhancedFASTGANGenerator(latent_dim=256, output_size=64).to(device)\n",
    "    discriminator = EnhancedFASTGANDiscriminator(input_size=64).to(device)\n",
    "    classifier = SyntheticImageClassifier(num_classes=num_classes, device=device)\n",
    "    \n",
    "    # Training parameters\n",
    "    num_epochs = 100\n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    # Train the model\n",
    "    generator, discriminator = train_enhanced_fastgan(\n",
    "        generator, discriminator, dataloader, \n",
    "        num_epochs=num_epochs, device=device\n",
    "    )\n",
    "    \n",
    "    # Generate synthetic images for each class\n",
    "    print(\"Generating synthetic images...\")\n",
    "    generate_synthetic_images(\n",
    "        generator, classifier, \n",
    "        num_classes=num_classes,\n",
    "        num_images_per_class=1000,  # Adjust as needed\n",
    "        device=device,\n",
    "        output_dir='synthetic_images'\n",
    "    )\n",
    "    \n",
    "    # Plot distribution comparison\n",
    "    plot_data_distribution_comparison(csv_file, 'synthetic_images')\n",
    "    \n",
    "    print(\"Training and generation complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4012.131448,
   "end_time": "2025-01-06T09:36:27.042012",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-06T08:29:34.910564",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
