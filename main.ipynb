{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import PyTorch, torchvision, FASTGAN, EfficientNetV2, ShuffleNetV2, and utility libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch and torchvision\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Import FASTGAN\n",
    "from fastgan import FastGAN\n",
    "\n",
    "# Import EfficientNetV2 and ShuffleNetV2\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import shufflenet_v2_x1_0\n",
    "\n",
    "# Import utility libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare HAM10000 Dataset\n",
    "Load the HAM10000 dataset, create data loaders, and organize images by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class HAM10000Dataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dirs, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dirs = img_dirs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx]['image_id'] + '.jpg'\n",
    "        for img_dir in self.img_dirs:\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            if os.path.exists(img_path):\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                label = self.data.iloc[idx]['dx']\n",
    "                return image, label\n",
    "        raise FileNotFoundError(f\"Image {img_name} not found in directories {self.img_dirs}\")\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "csv_file = 'HAM10000_metadata.csv'\n",
    "img_dirs = ['HAM10000_images_part_1', 'HAM10000_images_part_2']\n",
    "dataset = HAM10000Dataset(csv_file, img_dirs, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Organize images by class\n",
    "class_images = {}\n",
    "for img, label in dataset:\n",
    "    if label not in class_images:\n",
    "        class_images[label] = []\n",
    "    class_images[label].append(img)\n",
    "\n",
    "# Print the number of images per class\n",
    "for label, images in class_images.items():\n",
    "    print(f\"Class {label}: {len(images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup FASTGAN Configuration\n",
    "Configure FASTGAN parameters, set up the generator and discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup FASTGAN Configuration\n",
    "\n",
    "# Define FASTGAN parameters\n",
    "latent_dim = 128\n",
    "image_size = 224\n",
    "channels = 3\n",
    "\n",
    "# Initialize the generator and discriminator models\n",
    "generator = FastGAN.Generator(latent_dim, image_size, channels)\n",
    "discriminator = FastGAN.Discriminator(image_size, channels)\n",
    "\n",
    "# Print the generator and discriminator models\n",
    "print(generator)\n",
    "print(discriminator)\n",
    "\n",
    "# Define the optimizer for both generator and discriminator\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# Print the optimizers\n",
    "print(optimizer_G)\n",
    "print(optimizer_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Images\n",
    "Generate 1000 synthetic images per class using FASTGAN, save intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Synthetic Images\n",
    "\n",
    "# Function to generate synthetic images\n",
    "def generate_synthetic_images(generator, num_images, latent_dim, device):\n",
    "    generator.eval()\n",
    "    noise = torch.randn(num_images, latent_dim, 1, 1, device=device)\n",
    "    with torch.no_grad():\n",
    "        synthetic_images = generator(noise)\n",
    "    return synthetic_images\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator.to(device)\n",
    "\n",
    "# Generate 1000 synthetic images per class\n",
    "num_synthetic_images_per_class = 1000\n",
    "synthetic_images = {}\n",
    "\n",
    "for label in class_images.keys():\n",
    "    synthetic_images[label] = generate_synthetic_images(generator, num_synthetic_images_per_class, latent_dim, device)\n",
    "\n",
    "# Save synthetic images to disk\n",
    "output_dir = '/kaggle/working/synthetic_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for label, images in synthetic_images.items():\n",
    "    label_dir = os.path.join(output_dir, label)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    for i, img in enumerate(images):\n",
    "        img = (img * 0.5 + 0.5) * 255  # Denormalize the image\n",
    "        img = img.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_pil.save(os.path.join(label_dir, f\"{label}_{i}.png\"))\n",
    "\n",
    "print(\"Synthetic images generated and saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-trained Models\n",
    "Initialize and load pre-trained EfficientNetV2 and ShuffleNetV2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained Models\n",
    "\n",
    "# Initialize and load pre-trained EfficientNetV2 model\n",
    "efficientnet_model = EfficientNet.from_pretrained('efficientnet-v2-s')\n",
    "efficientnet_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize and load pre-trained ShuffleNetV2 model\n",
    "shufflenet_model = shufflenet_v2_x1_0(pretrained=True)\n",
    "shufflenet_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Move models to the appropriate device (GPU if available)\n",
    "efficientnet_model.to(device)\n",
    "shufflenet_model.to(device)\n",
    "\n",
    "# Print the models to verify they are loaded correctly\n",
    "print(efficientnet_model)\n",
    "print(shufflenet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Images\n",
    "Run inference on synthetic images using both classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Images\n",
    "\n",
    "# Function to classify images using a given model\n",
    "def classify_images(model, images, device):\n",
    "    model.eval()\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    return preds\n",
    "\n",
    "# Create a DataLoader for synthetic images\n",
    "synthetic_dataset = []\n",
    "for label, images in synthetic_images.items():\n",
    "    for img in images:\n",
    "        synthetic_dataset.append((img, label))\n",
    "\n",
    "synthetic_loader = DataLoader(synthetic_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Classify synthetic images using both models\n",
    "correctly_classified_images = []\n",
    "\n",
    "for images, labels in synthetic_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Classify with EfficientNetV2\n",
    "    efficientnet_preds = classify_images(efficientnet_model, images, device)\n",
    "    \n",
    "    # Classify with ShuffleNetV2\n",
    "    shufflenet_preds = classify_images(shufflenet_model, images, device)\n",
    "    \n",
    "    # Filter images that both models classify correctly\n",
    "    for i in range(len(images)):\n",
    "        if efficientnet_preds[i] == labels[i] and shufflenet_preds[i] == labels[i]:\n",
    "            correctly_classified_images.append((images[i], labels[i]))\n",
    "\n",
    "# Save filtered synthetic images to disk\n",
    "filtered_output_dir = '/kaggle/working/filtered_synthetic_images'\n",
    "os.makedirs(filtered_output_dir, exist_ok=True)\n",
    "\n",
    "for i, (img, label) in enumerate(correctly_classified_images):\n",
    "    img = (img * 0.5 + 0.5) * 255  # Denormalize the image\n",
    "    img = img.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(os.path.join(filtered_output_dir, f\"{label}_{i}.png\"))\n",
    "\n",
    "print(\"Filtered synthetic images saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Images\n",
    "Filter and keep only the synthetic images that both models classify correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Images\n",
    "\n",
    "# Function to classify images using a given model\n",
    "def classify_images(model, images, device):\n",
    "    model.eval()\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    return preds\n",
    "\n",
    "# Create a DataLoader for synthetic images\n",
    "synthetic_dataset = []\n",
    "for label, images in synthetic_images.items():\n",
    "    for img in images:\n",
    "        synthetic_dataset.append((img, label))\n",
    "\n",
    "synthetic_loader = DataLoader(synthetic_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Classify synthetic images using both models\n",
    "correctly_classified_images = []\n",
    "\n",
    "for images, labels in synthetic_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Classify with EfficientNetV2\n",
    "    efficientnet_preds = classify_images(efficientnet_model, images, device)\n",
    "    \n",
    "    # Classify with ShuffleNetV2\n",
    "    shufflenet_preds = classify_images(shufflenet_model, images, device)\n",
    "    \n",
    "    # Filter images that both models classify correctly\n",
    "    for i in range(len(images)):\n",
    "        if efficientnet_preds[i] == labels[i] and shufflenet_preds[i] == labels[i]:\n",
    "            correctly_classified_images.append((images[i], labels[i]))\n",
    "\n",
    "# Save filtered synthetic images to disk\n",
    "filtered_output_dir = '/kaggle/working/filtered_synthetic_images'\n",
    "os.makedirs(filtered_output_dir, exist_ok=True)\n",
    "\n",
    "for i, (img, label) in enumerate(correctly_classified_images):\n",
    "    img = (img * 0.5 + 0.5) * 255  # Denormalize the image\n",
    "    img = img.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(os.path.join(filtered_output_dir, f\"{label}_{i}.png\"))\n",
    "\n",
    "print(\"Filtered synthetic images saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Filtered Data\n",
    "Save the filtered synthetic images, training images, and test images to specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Filtered Data\n",
    "\n",
    "# Save filtered synthetic images to disk\n",
    "filtered_output_dir = '/kaggle/working/filtered_synthetic_images'\n",
    "os.makedirs(filtered_output_dir, exist_ok=True)\n",
    "\n",
    "for i, (img, label) in enumerate(correctly_classified_images):\n",
    "    img = (img * 0.5 + 0.5) * 255  # Denormalize the image\n",
    "    img = img.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(os.path.join(filtered_output_dir, f\"{label}_{i}.png\"))\n",
    "\n",
    "print(\"Filtered synthetic images saved successfully.\")\n",
    "\n",
    "# Save training images to disk\n",
    "train_output_dir = '/kaggle/working/train_images'\n",
    "os.makedirs(train_output_dir, exist_ok=True)\n",
    "\n",
    "for i, (img, label) in enumerate(dataset):\n",
    "    img = (img * 0.5 + 0.5) * 255  # Denormalize the image\n",
    "    img = img.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(os.path.join(train_output_dir, f\"{label}_{i}.png\"))\n",
    "\n",
    "print(\"Training images saved successfully.\")\n",
    "\n",
    "# Save test images to disk\n",
    "test_output_dir = '/kaggle/working/test_images'\n",
    "os.makedirs(test_output_dir, exist_ok=True)\n",
    "\n",
    "# Assuming test_dataset is defined and loaded similarly to dataset\n",
    "for i, (img, label) in enumerate(test_dataset):\n",
    "    img = (img * 0.5 + 0.5) * 255  # Denormalize the image\n",
    "    img = img.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(os.path.join(test_output_dir, f\"{label}_{i}.png\"))\n",
    "\n",
    "print(\"Test images saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
