{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torchvision.utils import save_image\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\n\nclass HAM10000Dataset(Dataset):\n    def __init__(self, csv_file, img_dirs, transform=None, device='cuda'):\n        self.data = pd.read_csv(csv_file)\n        self.img_dirs = img_dirs\n        self.transform = transform\n        self.device = device\n        \n        # Encode labels\n        self.label_encoder = LabelEncoder()\n        self.data['encoded_label'] = self.label_encoder.fit_transform(self.data['dx'])\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img_name = self.data.iloc[idx]['image_id'] + '.jpg'\n        for img_dir in self.img_dirs:\n            img_path = os.path.join(img_dir, img_name)\n            if os.path.exists(img_path):\n                image = Image.open(img_path).convert('RGB')\n                if self.transform:\n                    image = self.transform(image)\n                label = self.data.iloc[idx]['encoded_label']\n                return image, label\n        raise FileNotFoundError(f\"Image {img_name} not found in directories {self.img_dirs}\")\n\nclass FastGANGenerator(nn.Module):\n    def __init__(self, latent_dim=100, img_channels=3, num_classes=7, device='cuda'):\n        super(FastGANGenerator, self).__init__()\n        self.device = device\n        \n        # Condition embedding\n        self.label_embedding = nn.Embedding(num_classes, num_classes).to(device)\n        \n        # Generator architecture with conditional input\n        self.model = nn.Sequential(\n            nn.Linear(latent_dim + num_classes, 256),\n            nn.LeakyReLU(0.2),\n            nn.BatchNorm1d(256),\n            \n            nn.Linear(256, 512),\n            nn.LeakyReLU(0.2),\n            nn.BatchNorm1d(512),\n            \n            nn.Linear(512, 1024),\n            nn.LeakyReLU(0.2),\n            nn.BatchNorm1d(1024),\n            \n            nn.Linear(1024, img_channels * 64 * 64),\n            nn.Tanh()\n        ).to(device)\n    \n    def forward(self, z, labels):\n        # Ensure z and labels are on the correct device\n        z = z.to(self.device)\n        labels = labels.to(self.device)\n        \n        # Embed labels\n        label_embed = self.label_embedding(labels)\n        \n        # Concatenate noise and label embedding\n        conditional_input = torch.cat([z, label_embed], dim=1)\n        \n        # Generate images\n        img = self.model(conditional_input)\n        img = img.view(img.size(0), 3, 64, 64)\n        return img\n\nclass FastGANDiscriminator(nn.Module):\n    def __init__(self, img_channels=3, num_classes=7, device='cuda'):\n        super(FastGANDiscriminator, self).__init__()\n        self.device = device\n        \n        # Label embedding\n        self.label_embedding = nn.Embedding(num_classes, num_classes).to(device)\n        \n        self.model = nn.Sequential(\n            nn.Linear(img_channels * 64 * 64 + num_classes, 1024),\n            nn.LeakyReLU(0.2),\n            nn.Dropout(0.3),\n            \n            nn.Linear(1024, 512),\n            nn.LeakyReLU(0.2),\n            nn.Dropout(0.3),\n            \n            nn.Linear(512, 1),\n            nn.Sigmoid()\n        ).to(device)\n    \n    def forward(self, img, labels):\n        # Ensure img and labels are on the correct device\n        img = img.to(self.device)\n        labels = labels.to(self.device)\n        \n        # Flatten image\n        img_flat = img.view(img.size(0), -1)\n        \n        # Embed labels\n        label_embed = self.label_embedding(labels)\n        \n        # Concatenate image and label embedding\n        conditional_input = torch.cat([img_flat, label_embed], dim=1)\n        \n        # Compute validity\n        validity = self.model(conditional_input)\n        return validity\n\ndef train_fastgan(generator, discriminator, dataloader, num_epochs=1):\n    \"\"\"\n    Train Conditional FASTGAN\n    \"\"\"\n    device = generator.device\n    \n    # Optimizers\n    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    \n    # Loss functions\n    adversarial_loss = nn.BCELoss()\n    \n    for epoch in range(num_epochs):\n        for real_images, labels in dataloader:\n            real_images = real_images.to(device)\n            labels = labels.to(device)\n            batch_size = real_images.size(0)\n            \n            # Adversarial ground truths\n            valid = torch.ones(batch_size, 1).to(device)\n            fake = torch.zeros(batch_size, 1).to(device)\n            \n            # Train Generator\n            g_optimizer.zero_grad()\n            \n            # Sample noise and labels\n            z = torch.randn(batch_size, 100).to(device)\n            gen_labels = torch.randint(0, len(generator.label_embedding.weight), (batch_size,)).to(device)\n            \n            # Generate images\n            generated_images = generator(z, gen_labels)\n            \n            # Generator loss\n            g_loss = adversarial_loss(discriminator(generated_images, gen_labels), valid)\n            \n            g_loss.backward()\n            g_optimizer.step()\n            \n            # Train Discriminator\n            d_optimizer.zero_grad()\n            \n            # Real images loss\n            real_loss = adversarial_loss(discriminator(real_images, labels), valid)\n            \n            # Fake images loss\n            fake_loss = adversarial_loss(discriminator(generated_images.detach(), gen_labels), fake)\n            \n            # Total discriminator loss\n            d_loss = (real_loss + fake_loss) / 2\n            \n            d_loss.backward()\n            d_optimizer.step()\n        \n        # Print epoch statistics\n        print(f\"Epoch [{epoch+1}/{num_epochs}], G Loss: {g_loss.item():.4f}, D Loss: {d_loss.item():.4f}\")\n    \n    return generator\n\ndef main():\n    # Determine device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Set random seed for reproducibility\n    torch.manual_seed(42)\n    np.random.seed(42)\n    \n    # Transforms\n    transform = transforms.Compose([\n        transforms.Resize((64, 64)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n    \n    # 1. Prepare HAM10000 Dataset\n    csv_file = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n    img_dirs = ['/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1', '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2']\n    \n    # Create dataset and data loader\n    dataset = HAM10000Dataset(csv_file, img_dirs, transform=transform, device=device)\n    \n    # Get number of classes\n    num_classes = len(dataset.label_encoder.classes_)\n    print(\"Unique Classes:\", dataset.label_encoder.classes_)\n    print(\"Number of Classes:\", num_classes)\n    \n    # Create data loader\n    batch_size = 64\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n    \n    # 2. Setup FASTGAN Configuration\n    generator = FastGANGenerator(num_classes=num_classes, device=device)\n    discriminator = FastGANDiscriminator(num_classes=num_classes, device=device)\n    \n    # 3. Train FASTGAN and Generate 1000 Synthetic Images\n    trained_generator = train_fastgan(generator, discriminator, data_loader)\n    \n    # Generate synthetic images\n    os.makedirs('synthetic_images', exist_ok=True)\n    \n    # Generate images for each class\n    synthetic_images_by_class = {}\n    \n    with torch.no_grad():\n        for class_idx in range(num_classes):\n            # Generate 100 images for each class\n            z = torch.randn(100, 100).to(device)\n            class_labels = torch.full((100,), class_idx, dtype=torch.long).to(device)\n            \n            synthetic_images = trained_generator(z, class_labels)\n            \n            # Save images\n            synthetic_images_by_class[class_idx] = synthetic_images.cpu()\n            \n            # Save images to disk\n            class_name = dataset.label_encoder.inverse_transform([class_idx])[0]\n            class_dir = os.path.join('synthetic_images', class_name)\n            os.makedirs(class_dir, exist_ok=True)\n            \n            for i, img in enumerate(synthetic_images):\n                save_path = os.path.join(class_dir, f'synthetic_image_{i}.png')\n                save_image((img * 0.5 + 0.5), save_path)\n    \n    print(\"Synthetic image generation and filtering complete!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:02:24.498165Z","iopub.execute_input":"2024-12-13T09:02:24.498504Z","iopub.status.idle":"2024-12-13T09:02:58.802280Z","shell.execute_reply.started":"2024-12-13T09:02:24.498474Z","shell.execute_reply":"2024-12-13T09:02:58.801291Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nUnique Classes: ['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc']\nNumber of Classes: 7\nEpoch [1/1], G Loss: 3.6399, D Loss: 0.2509\nSynthetic image generation and filtering complete!\n","output_type":"stream"}],"execution_count":15}]}