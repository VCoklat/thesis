{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F \nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torchvision.utils import save_image\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\n\nclass HAM10000Dataset(Dataset):\n    def __init__(self, csv_file, img_dirs, transform=None, device='cuda'):\n        self.data = pd.read_csv(csv_file)\n        self.img_dirs = img_dirs\n        self.transform = transform\n        self.device = device\n        \n        # Encode labels\n        self.label_encoder = LabelEncoder()\n        self.data['encoded_label'] = self.label_encoder.fit_transform(self.data['dx'])\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img_name = self.data.iloc[idx]['image_id'] + '.jpg'\n        for img_dir in self.img_dirs:\n            img_path = os.path.join(img_dir, img_name)\n            if os.path.exists(img_path):\n                image = Image.open(img_path).convert('RGB')\n                if self.transform:\n                    image = self.transform(image)\n                label = self.data.iloc[idx]['encoded_label']\n                return image, label\n        raise FileNotFoundError(f\"Image {img_name} not found in directories {self.img_dirs}\")\n\nclass SLEBlock(nn.Module):\n    def __init__(self, in_channels):\n        super(SLEBlock, self).__init__()\n        self.global_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(in_channels, in_channels // 2, 1)\n        self.fc2 = nn.Conv2d(in_channels // 2, in_channels, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x, y):\n        x = self.global_pool(x)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return y * x\n        \nclass FASTGANGenerator(nn.Module):\n    def __init__(self, latent_dim=256, ngf=64, output_size=64):\n        super(FASTGANGenerator, self).__init__()\n        self.output_size = output_size\n        self.initial = nn.Sequential(\n            nn.ConvTranspose2d(latent_dim, ngf * 16, 4, 1, 0),\n            nn.BatchNorm2d(ngf * 16),\n            nn.ReLU(True)\n        )\n        self.layer1 = nn.Sequential(\n            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True)\n        )\n        self.sle1 = SLEBlock(ngf * 8)\n        self.layer2 = nn.Sequential(\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True)\n        )\n        self.sle2 = SLEBlock(ngf * 4)\n        self.layer3 = nn.Sequential(\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True)\n        )\n        self.layer4 = nn.Sequential(\n            nn.ConvTranspose2d(ngf * 2, 3, 4, 2, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        x = self.initial(z)\n        x = self.layer1(x)\n        x = self.sle1(x, x)\n        x = self.layer2(x)\n        x = self.sle2(x, x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\nclass FASTGANDiscriminator(nn.Module):\n    def __init__(self, ndf=64, input_size=64):\n        super(FASTGANDiscriminator, self).__init__()\n        self.input_size = input_size\n        self.main = nn.Sequential(\n            nn.Conv2d(3, ndf, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(ndf * 8, 1, 1),\n            nn.Flatten(),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.main(x)\n\nclass SelfSupervisedDiscriminator(nn.Module):\n    def __init__(self, ndf=64):\n        super(SelfSupervisedDiscriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(3, ndf, 4, 2, 1),          # 16x16 -> 8x8\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1),   # 8x8 -> 4x4\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1),  # 4x4 -> 2x2\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1),  # 2x2 -> 1x1\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf * 8, ndf * 16, 1, 1, 0), # 1x1 -> 1x1\n            nn.BatchNorm2d(ndf * 16),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf * 16, 1, 1, 1, 0),      # 1x1 -> 1x1\n            nn.Sigmoid()\n        )\n        \n        # Small decoders for self-supervised learning\n        self.decoder1 = nn.Sequential(\n            nn.ConvTranspose2d(ndf * 16, ndf * 8, 4, 1, 0),   # 1x1 -> 2x2\n            nn.BatchNorm2d(ndf * 8),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ndf * 8, ndf * 4, 4, 2, 1),    # 2x2 -> 4x4\n            nn.BatchNorm2d(ndf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ndf * 4, ndf * 2, 4, 2, 1),    # 4x4 -> 8x8\n            nn.BatchNorm2d(ndf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ndf * 2, 3, 4, 2, 1),          # 8x8 -> 16x16\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        features = self.main[:-1](x)            # Extract features before the final layer\n        validity = self.main[-1](features)      # Compute validity score\n        reconstruction = self.decoder1(features) # Reconstruct the image\n        \n        # Debugging Statements\n        print(f\"Input Image Size: {x.size()}\")\n        print(f\"Reconstructed Image Size: {reconstruction.size()}\")\n        \n        return validity, reconstruction\n\ndef train_step(real_imgs, generator, discriminator, g_optimizer, d_optimizer, \n               device, autoencoder_loss):\n    batch_size = real_imgs.size(0)\n    \n    # Train Discriminator\n    d_optimizer.zero_grad()\n    \n    real_validity = discriminator(real_imgs)\n    \n    z = torch.randn(batch_size, 256, 1, 1, device=device)\n    fake_imgs = generator(z)\n    fake_validity = discriminator(fake_imgs.detach())\n    \n    d_loss = (F.binary_cross_entropy(real_validity, torch.ones_like(real_validity)) +\n              F.binary_cross_entropy(fake_validity, torch.zeros_like(fake_validity)))\n    \n    d_loss.backward()\n    d_optimizer.step()\n    \n    # Train Generator\n    g_optimizer.zero_grad()\n    \n    fake_validity = discriminator(fake_imgs)\n    g_loss = F.binary_cross_entropy(fake_validity, torch.ones_like(fake_validity))\n    \n    g_loss.backward()\n    g_optimizer.step()\n    \n    return d_loss.item(), g_loss.item(), fake_imgs\n\ndef train_fastgan(generator, discriminator, dataloader, num_epochs, device='cuda'):\n    g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    \n    autoencoder_loss = nn.MSELoss()\n    \n    for epoch in range(num_epochs):\n        for i, (real_imgs, _) in enumerate(dataloader):\n            real_imgs = real_imgs.to(device)\n            \n            d_loss, g_loss, fake_imgs = train_step(real_imgs, generator, discriminator, \n                                                   g_optimizer, d_optimizer, \n                                                   device, autoencoder_loss)\n            \n            if i % 100 == 0:\n                print(f'Epoch [{epoch}/{num_epochs}], '\n                      f'D_loss: {d_loss:.4f}, G_loss: {g_loss:.4f}')\n                \n                # Optional: Save some generated images\n                if i % 500 == 0:\n                    save_image(fake_imgs[:16] * 0.5 + 0.5, \n                               f'generated_images_epoch_{epoch}_batch_{i}.png', \n                               normalize=False)\n\nclass ProgressiveGrowingManager:\n    def __init__(self, start_size=16, target_size=64, n_steps=3):\n        self.current_size = start_size\n        self.target_size = target_size\n        self.n_steps = n_steps\n        self.alpha = 0.0\n        \n    def step(self):\n        self.alpha = min(1.0, self.alpha + 0.1)\n        if self.alpha >= 1.0 and self.current_size < self.target_size:\n            self.current_size = min(self.current_size * 2, self.target_size)\n            self.alpha = 0.0\n            \n    def get_size(self):\n        return self.current_size\n\nclass SyntheticImageClassifier:\n    def __init__(self, num_classes, device='cuda'):\n        self.device = device\n        \n        # EfficientNetV2\n        self.efficientnet = models.efficientnet_v2_s(pretrained=True)\n        self.efficientnet.classifier[1] = nn.Linear(self.efficientnet.classifier[1].in_features, num_classes)\n        self.efficientnet = self.efficientnet.to(device)\n        \n        # ShuffleNetV2\n        self.shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n        self.shufflenet.fc = nn.Linear(self.shufflenet.fc.in_features, num_classes)\n        self.shufflenet = self.shufflenet.to(device)\n        \n        # Transformation for input images\n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        \n    def load_pretrained_weights(self, efficientnet_path, shufflenet_path):\n        \"\"\"\n        Load pretrained weights for both models\n        \n        Args:\n            efficientnet_path (str): Path to EfficientNetV2 weights\n            shufflenet_path (str): Path to ShuffleNetV2 weights\n        \"\"\"\n        self.efficientnet.load_state_dict(torch.load(efficientnet_path))\n        self.shufflenet.load_state_dict(torch.load(shufflenet_path))\n        \n        # Set models to evaluation mode\n        self.efficientnet.eval()\n        self.shufflenet.eval()\n    \n    def classify_synthetic_images(self, synthetic_images):\n        \"\"\"\n        Classify synthetic images using both models\n        \n        Args:\n            synthetic_images (torch.Tensor): Tensor of synthetic images\n        \n        Returns:\n            torch.Tensor: Mask of correctly classified images\n        \"\"\"\n        # Resize and normalize synthetic images for classification\n        resized_images = F.interpolate(synthetic_images, size=(224, 224), mode='bilinear', align_corners=False)\n        normalized_images = (resized_images - resized_images.min()) / (resized_images.max() - resized_images.min())\n        normalized_images = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(normalized_images)\n        \n        # Get predictions from both models\n        with torch.no_grad():\n            efficientnet_preds = self.efficientnet(normalized_images)\n            shufflenet_preds = self.shufflenet(normalized_images)\n        \n        # Get class predictions\n        efficientnet_classes = torch.argmax(efficientnet_preds, dim=1)\n        shufflenet_classes = torch.argmax(shufflenet_preds, dim=1)\n        \n        # Create mask where both models agree\n        agreed_classification_mask = (efficientnet_classes == shufflenet_classes)\n        \n        return agreed_classification_mask\n\ndef main():\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    torch.manual_seed(42)\n    np.random.seed(42)\n    \n    transform = transforms.Compose([\n        transforms.Resize((64, 64)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n    \n    csv_file = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n    img_dirs = ['/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1', '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2']\n    \n    dataset = HAM10000Dataset(csv_file, img_dirs, transform=transform, device=device)\n    \n    num_classes = len(dataset.label_encoder.classes_)\n    print(\"Unique Classes:\", dataset.label_encoder.classes_)\n    print(\"Number of Classes:\", num_classes)\n    \n    batch_size = 64\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n    \n    latent_dim = 256\n    generator = FASTGANGenerator(latent_dim, output_size=64).to(device)\n    discriminator = FASTGANDiscriminator(input_size=64).to(device)\n    \n    num_epochs = 1\n    \n    train_fastgan(generator, discriminator, data_loader, num_epochs, device)\n    \n    os.makedirs('synthetic_images', exist_ok=True)\n    \n    # Initialize the Synthetic Image Classifier\n    classifier = SyntheticImageClassifier(num_classes=num_classes, device=device)\n    \n    # Note: In a real scenario, you would load pretrained weights\n    # classifier.load_pretrained_weights('path/to/efficientnet_weights.pth', 'path/to/shufflenet_weights.pth')\n    \n    synthetic_images_by_class = {}\n    \n    with torch.no_grad():\n        for class_idx in range(num_classes):\n            z = torch.randn(100, latent_dim, 1, 1).to(device)\n            synthetic_images = generator(z)\n            \n            # Classify synthetic images\n            valid_image_mask = classifier.classify_synthetic_images(synthetic_images)\n            \n            # Filter synthetic images based on classification\n            valid_synthetic_images = synthetic_images[valid_image_mask]\n            \n            synthetic_images_by_class[class_idx] = valid_synthetic_images.cpu()\n            \n            class_name = dataset.label_encoder.inverse_transform([class_idx])[0]\n            class_dir = os.path.join('synthetic_images', class_name)\n            os.makedirs(class_dir, exist_ok=True)\n            \n            for i, img in enumerate(valid_synthetic_images):\n                save_path = os.path.join(class_dir, f'synthetic_image_{i}.png')\n                save_image((img * 0.5 + 0.5), save_path)\n    \n    print(\"Synthetic image generation, classification, and filtering complete!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T16:39:25.179612Z","iopub.execute_input":"2024-12-13T16:39:25.180016Z","iopub.status.idle":"2024-12-13T16:40:09.405065Z","shell.execute_reply.started":"2024-12-13T16:39:25.179984Z","shell.execute_reply":"2024-12-13T16:40:09.404021Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nUnique Classes: ['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc']\nNumber of Classes: 7\nEpoch [0/1], D_loss: 1.4208, G_loss: 0.5995\nEpoch [0/1], D_loss: 0.5373, G_loss: 1.5907\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n100%|██████████| 82.7M/82.7M [00:00<00:00, 201MB/s]\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x1-5666bf0f80.pth\n100%|██████████| 8.79M/8.79M [00:00<00:00, 138MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Synthetic image generation, classification, and filtering complete!\n","output_type":"stream"}],"execution_count":6}]}