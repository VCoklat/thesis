{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torchvision.utils import save_image\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\n\nclass HAM10000Dataset(Dataset):\n    def __init__(self, csv_file, img_dirs, transform=None, device='cuda'):\n        self.data = pd.read_csv(csv_file)\n        self.img_dirs = img_dirs\n        self.transform = transform\n        self.device = device\n        \n        # Encode labels\n        self.label_encoder = LabelEncoder()\n        self.data['encoded_label'] = self.label_encoder.fit_transform(self.data['dx'])\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img_name = self.data.iloc[idx]['image_id'] + '.jpg'\n        for img_dir in self.img_dirs:\n            img_path = os.path.join(img_dir, img_name)\n            if os.path.exists(img_path):\n                image = Image.open(img_path).convert('RGB')\n                if self.transform:\n                    image = self.transform(image)\n                label = self.data.iloc[idx]['encoded_label']\n                return image, label\n        raise FileNotFoundError(f\"Image {img_name} not found in directories {self.img_dirs}\")\n\nclass SLEBlock(nn.Module):\n    def __init__(self, in_channels):\n        super(SLEBlock, self).__init__()\n        self.global_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(in_channels, in_channels // 2, 1)\n        self.fc2 = nn.Conv2d(in_channels // 2, in_channels, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x, y):\n        x = self.global_pool(x)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return y * x\n\nclass FASTGANGenerator(nn.Module):\n    def __init__(self, latent_dim=256, ngf=64):\n        super(FASTGANGenerator, self).__init__()\n        self.initial = nn.Sequential(\n            nn.ConvTranspose2d(latent_dim, ngf * 16, 4, 1, 0),\n            nn.BatchNorm2d(ngf * 16),\n            nn.ReLU(True)\n        )\n        self.layer1 = nn.Sequential(\n            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True)\n        )\n        self.sle1 = SLEBlock(ngf * 8)\n        self.layer2 = nn.Sequential(\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True)\n        )\n        self.sle2 = SLEBlock(ngf * 4)\n        self.layer3 = nn.Sequential(\n            nn.ConvTranspose2d(ngf * 4, 3, 4, 2, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        x = self.initial(z)\n        x = self.layer1(x)\n        x = self.sle1(x, x)\n        x = self.layer2(x)\n        x = self.sle2(x, x)\n        x = self.layer3(x)\n        return x\n\nclass FASTGANDiscriminator(nn.Module):\n    def __init__(self, ndf=64):\n        super(FASTGANDiscriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(3, ndf, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(ndf * 2, 1, 1),\n            nn.Flatten(),\n            nn.Sigmoid()\n        )\n        self.auxiliary = nn.Sequential(\n            nn.Conv2d(3, ndf, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(ndf * 2, 1, 1),\n            nn.Flatten(),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        downsampled = F.interpolate(x, scale_factor=0.5)\n        main_out = self.main(x)\n        aux_out = self.auxiliary(downsampled)\n        return main_out, aux_out\n\nclass FeatureMatchingLoss(nn.Module):\n    def __init__(self):\n        super(FeatureMatchingLoss, self).__init__()\n        self.l1_loss = nn.L1Loss()\n        \n    def forward(self, real_features, fake_features):\n        loss = 0\n        for real_feat, fake_feat in zip(real_features, fake_features):\n            loss += self.l1_loss(fake_feat, real_feat.detach())\n        return loss\n\nclass MemoryBank:\n    def __init__(self, max_size=1000, feature_dim=256):\n        self.max_size = max_size\n        self.features = []\n        self.feature_dim = feature_dim\n        \n    def update(self, new_features):\n        self.features.extend(new_features.detach().cpu())\n        if len(self.features) > self.max_size:\n            self.features = self.features[-self.max_size:]\n            \n    def sample(self, n_samples):\n        if len(self.features) == 0:\n            return torch.randn(n_samples, self.feature_dim)\n        indices = torch.randint(0, len(self.features), (n_samples,))\n        return torch.stack([self.features[i] for i in indices])\n\nclass ProgressiveGrowingManager:\n    def __init__(self, start_size=16, target_size=224, n_steps=4):\n        self.current_size = start_size\n        self.target_size = target_size\n        self.n_steps = n_steps\n        self.alpha = 0.0\n        \n    def step(self):\n        self.alpha = min(1.0, self.alpha + 0.1)\n        if self.alpha >= 1.0 and self.current_size < self.target_size:\n            self.current_size = min(self.current_size * 2, self.target_size)\n            self.alpha = 0.0\n            \n    def get_size(self):\n        return self.current_size\n\ndef train_step(real_imgs, generator, discriminator, g_optimizer, d_optimizer, \n               feature_matching, memory_bank, prog_manager):\n    batch_size = real_imgs.size(0)\n    real_imgs = F.interpolate(real_imgs, size=prog_manager.get_size())\n    d_optimizer.zero_grad()\n    real_main, real_aux = discriminator(real_imgs)\n    z = torch.randn(batch_size, 256, 1, 1, device=real_imgs.device)\n    fake_imgs = generator(z)\n    fake_main, fake_aux = discriminator(fake_imgs.detach())\n    d_loss = (F.binary_cross_entropy(real_main, torch.ones_like(real_main)) +\n              F.binary_cross_entropy(real_aux, torch.ones_like(real_aux)) +\n              F.binary_cross_entropy(fake_main, torch.zeros_like(fake_main)) +\n              F.binary_cross_entropy(fake_aux, torch.zeros_like(fake_aux)))\n    d_loss.backward()\n    d_optimizer.step()\n    g_optimizer.zero_grad()\n    fake_main, fake_aux = discriminator(fake_imgs)\n    g_loss = (F.binary_cross_entropy(fake_main, torch.ones_like(fake_main)) +\n              F.binary_cross_entropy(fake_aux, torch.ones_like(fake_aux)) +\n              feature_matching(real_main, fake_main))\n    g_loss.backward()\n    g_optimizer.step()\n    memory_bank.update(fake_imgs)\n    prog_manager.step()\n    return d_loss.item(), g_loss.item()\n\ndef train_fastgan(generator, discriminator, dataloader, num_epochs, progressive_steps=[16], device='cuda'):\n    g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n    feature_matching = FeatureMatchingLoss()\n    memory_bank = MemoryBank()\n    prog_manager = ProgressiveGrowingManager()\n    \n    for step in progressive_steps:\n        for epoch in range(num_epochs):\n            for i, (real_imgs, _) in enumerate(dataloader):\n                real_imgs = real_imgs.to(device)\n                d_loss, g_loss = train_step(real_imgs, generator, discriminator, g_optimizer, d_optimizer, \n                                           feature_matching, memory_bank, prog_manager)\n                if i % 100 == 0:\n                    print(f'Step: {step}, Epoch [{epoch}/{num_epochs}], '\n                          f'D_loss: {d_loss:.4f}, G_loss: {g_loss:.4f}')\n\ndef main():\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    torch.manual_seed(42)\n    np.random.seed(42)\n    \n    transform = transforms.Compose([\n        transforms.Resize((64, 64)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n    \n    csv_file = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n    img_dirs = ['/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1', '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2']\n    \n    dataset = HAM10000Dataset(csv_file, img_dirs, transform=transform, device=device)\n    \n    num_classes = len(dataset.label_encoder.classes_)\n    print(\"Unique Classes:\", dataset.label_encoder.classes_)\n    print(\"Number of Classes:\", num_classes)\n    \n    batch_size = 64\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n    \n    latent_dim = 256\n    generator = FASTGANGenerator(latent_dim).to(device)\n    discriminator = FASTGANDiscriminator().to(device)\n    \n    num_epochs = 1\n    progressive_steps = [16]\n    \n    train_fastgan(generator, discriminator, data_loader, num_epochs, progressive_steps, device)\n    \n    os.makedirs('synthetic_images', exist_ok=True)\n    \n    synthetic_images_by_class = {}\n    \n    with torch.no_grad():\n        for class_idx in range(num_classes):\n            z = torch.randn(100, latent_dim, 1, 1).to(device)\n            synthetic_images = generator(z)\n            \n            synthetic_images_by_class[class_idx] = synthetic_images.cpu()\n            \n            class_name = dataset.label_encoder.inverse_transform([class_idx])[0]\n            class_dir = os.path.join('synthetic_images', class_name)\n            os.makedirs(class_dir, exist_ok=True)\n            \n            for i, img in enumerate(synthetic_images):\n                save_path = os.path.join(class_dir, f'synthetic_image_{i}.png')\n                save_image((img * 0.5 + 0.5), save_path)\n    \n    print(\"Synthetic image generation and filtering complete!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T14:42:02.214014Z","iopub.execute_input":"2024-12-13T14:42:02.214538Z","iopub.status.idle":"2024-12-13T14:42:53.815659Z","shell.execute_reply.started":"2024-12-13T14:42:02.214503Z","shell.execute_reply":"2024-12-13T14:42:53.814651Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Using device: cuda\nUnique Classes: ['akiec' 'bcc' 'bkl' 'df' 'mel' 'nv' 'vasc']\nNumber of Classes: 7\nStep: 16, Epoch [0/1], D_loss: 2.7883, G_loss: 3.7204\nStep: 16, Epoch [0/1], D_loss: 1.9488, G_loss: 17.9825\nSynthetic image generation and filtering complete!\n","output_type":"stream"}],"execution_count":3}]}